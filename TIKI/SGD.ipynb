{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu (giả sử có file review.csv với các cột user_id, product_id, rating)\n",
    "review_data = pd.read_csv(r\"C:\\Users\\anhn2\\Documents\\DJANGO\\DA\\TIKI\\comments_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển dữ liệu thành ma trận người dùng - sản phẩm (user-item matrix).\n",
    "n_users = review_data['user_id'].nunique()\n",
    "n_items = review_data['product_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển đổi user_id và product_id thành chỉ số (index)\n",
    "user_mapping = {user_id: index for index, user_id in enumerate(review_data['user_id'].unique())}\n",
    "item_mapping = {product_id: index for index, product_id in enumerate(review_data['product_id'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ma trận đánh giá\n",
    "ratings_matrix = np.zeros((n_users, n_items))\n",
    "for row in review_data.itertuples():\n",
    "    ratings_matrix[user_mapping[row.user_id], item_mapping[row.product_id]] = row.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo các yếu tố ẩn (user and item factors) và bias\n",
    "n_factors = 20  # Số lượng yếu tố ẩn\n",
    "\n",
    "# Các tham số SGD cần thử nghiệm\n",
    "learning_rates = [0.0001, 0.001, 0.005]  # Giảm giá trị learning rate\n",
    "regularizations = [0.01, 0.05, 0.1]  # Thử giá trị regularization cao hơn\n",
    "n_epochs_values = [20, 30, 50]  # Cải thiện số epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm chung cho cả có và không có bias\n",
    "def sgd(matrix, user_factors, item_factors, user_bias=None, item_bias=None, global_bias=None, learning_rate=0.01, regularization=0.1, n_epochs=100, with_bias=False):\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0\n",
    "        for i in range(n_users):\n",
    "            for j in range(n_items):\n",
    "                if matrix[i, j] > 0:  # Chỉ tính với các giá trị không bằng 0 (có rating)\n",
    "                    if with_bias:\n",
    "                        # Tính toán dự đoán (bao gồm bias)\n",
    "                        prediction = global_bias + user_bias[i] + item_bias[j] + np.dot(user_factors[i, :], item_factors[j, :].T)\n",
    "                    else:\n",
    "                        # Tính toán dự đoán không có bias\n",
    "                        prediction = np.dot(user_factors[i, :], item_factors[j, :].T)\n",
    "                    \n",
    "                    # Tính lỗi (error)\n",
    "                    error = matrix[i, j] - prediction\n",
    "                    total_loss += error**2\n",
    "                    \n",
    "                    # Cập nhật các yếu tố ẩn và bias (nếu có)\n",
    "                    user_factors[i, :] += learning_rate * (error * item_factors[j, :] - regularization * user_factors[i, :])\n",
    "                    item_factors[j, :] += learning_rate * (error * user_factors[i, :] - regularization * item_factors[j, :])\n",
    "                    \n",
    "                    if with_bias:\n",
    "                        user_bias[i] += learning_rate * (error - regularization * user_bias[i])\n",
    "                        item_bias[j] += learning_rate * (error - regularization * item_bias[j])\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs} - Loss: {total_loss}\")\n",
    "    \n",
    "    return user_factors, item_factors, user_bias, item_bias\n",
    "# Hàm tính RMSE (Root Mean Squared Error) để đánh giá mô hình\n",
    "def rmse(matrix, predictions):\n",
    "    non_zero_indices = matrix > 0\n",
    "    mse = mean_squared_error(matrix[non_zero_indices], predictions[non_zero_indices])\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm tính RMSE (Root Mean Squared Error) để đánh giá mô hình\n",
    "def rmse(matrix, predictions):\n",
    "    non_zero_indices = matrix > 0\n",
    "    mse = mean_squared_error(matrix[non_zero_indices], predictions[non_zero_indices])\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm chạy thí nghiệm với và không có bias\n",
    "def run_experiment(learning_rates, regularizations, n_epochs_values, with_bias=False):\n",
    "    best_rmse = float('inf')\n",
    "    best_params = None\n",
    "    best_user_factors = None\n",
    "    best_item_factors = None\n",
    "    best_user_bias = None\n",
    "    best_item_bias = None\n",
    "    global_bias = np.mean(ratings_matrix[ratings_matrix > 0]) if with_bias else None\n",
    "\n",
    "    # Tạo một DataFrame để lưu kết quả\n",
    "    results_df = []\n",
    "    \n",
    "    for lr in learning_rates:\n",
    "        for reg in regularizations:\n",
    "            for n_epochs in n_epochs_values:\n",
    "\n",
    "                # Khởi tạo các yếu tố ẩn và bias\n",
    "                user_factors = np.random.normal(0, 0.1, (n_users, n_factors))\n",
    "                item_factors = np.random.normal(0, 0.1, (n_items, n_factors))\n",
    "                user_bias = np.zeros(n_users) if with_bias else None\n",
    "                item_bias = np.zeros(n_items) if with_bias else None\n",
    "\n",
    "                # Chạy SGD\n",
    "                user_factors, item_factors, user_bias, item_bias = sgd(\n",
    "                    ratings_matrix, user_factors, item_factors, user_bias, item_bias, global_bias, lr, reg, n_epochs, with_bias\n",
    "                )\n",
    "\n",
    "                # Dự đoán kết quả\n",
    "                predictions = global_bias + user_bias[:, np.newaxis] + item_bias[np.newaxis, :] + np.dot(user_factors, item_factors.T) if with_bias else np.dot(user_factors, item_factors.T)\n",
    "\n",
    "                # Đánh giá mô hình\n",
    "                error = rmse(ratings_matrix, predictions)\n",
    "                print(f\"RMSE with bias={with_bias}: {error}\")\n",
    "                \n",
    "                # Lưu kết quả vào DataFrame\n",
    "                results_df = results_df.append({\n",
    "                    'learning_rate': lr,\n",
    "                    'regularization': reg,\n",
    "                    'epochs': n_epochs,\n",
    "                    'rmse': error\n",
    "                }, ignore_index=True)\n",
    "                \n",
    "                # Lưu lại mô hình với RMSE thấp nhất\n",
    "                if error < best_rmse:\n",
    "                    best_rmse = error\n",
    "                    best_params = (lr, reg, n_epochs)\n",
    "                    best_user_factors = user_factors\n",
    "                    best_item_factors = item_factors\n",
    "                    best_user_bias = user_bias\n",
    "                    best_item_bias = item_bias\n",
    "                \n",
    "\n",
    "    print(f\"\\nBest model with bias={with_bias} found:\")\n",
    "    print(f\"Learning Rate: {best_params[0]}, Regularization: {best_params[1]}, Epochs: {best_params[2]}\")\n",
    "    print(f\"Best RMSE with bias={with_bias}: {best_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Loss: 260088.3345048007\n",
      "Epoch 2/20 - Loss: 260067.9587914076\n",
      "Epoch 3/20 - Loss: 260047.60058492306\n",
      "Epoch 4/20 - Loss: 260027.25656172785\n",
      "Epoch 5/20 - Loss: 260006.9234103933\n",
      "Epoch 6/20 - Loss: 259986.59782988514\n",
      "Epoch 7/20 - Loss: 259966.27652776538\n",
      "Epoch 8/20 - Loss: 259945.9562184041\n",
      "Epoch 9/20 - Loss: 259925.6336212184\n",
      "Epoch 10/20 - Loss: 259905.30545888765\n",
      "Epoch 11/20 - Loss: 259884.9684556026\n",
      "Epoch 12/20 - Loss: 259864.619335307\n",
      "Epoch 13/20 - Loss: 259844.25481995192\n",
      "Epoch 14/20 - Loss: 259823.87162773678\n",
      "Epoch 15/20 - Loss: 259803.46647136667\n",
      "Epoch 16/20 - Loss: 259783.03605630837\n",
      "Epoch 17/20 - Loss: 259762.57707904055\n",
      "Epoch 18/20 - Loss: 259742.0862253025\n",
      "Epoch 19/20 - Loss: 259721.56016833533\n",
      "Epoch 20/20 - Loss: 259700.99556713292\n",
      "RMSE with bias=False: 4.567956573124355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anhn2\\AppData\\Local\\Temp\\ipykernel_28404\\318348777.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, new_row_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - Loss: 260200.01927177902\n",
      "Epoch 2/30 - Loss: 260179.99661325334\n",
      "Epoch 3/30 - Loss: 260159.984534492\n",
      "Epoch 4/30 - Loss: 260139.98015842715\n",
      "Epoch 5/30 - Loss: 260119.98061920915\n",
      "Epoch 6/30 - Loss: 260099.98306071103\n",
      "Epoch 7/30 - Loss: 260079.98463505105\n",
      "Epoch 8/30 - Loss: 260059.98250114077\n",
      "Epoch 9/30 - Loss: 260039.97382322518\n",
      "Epoch 10/30 - Loss: 260019.9557694475\n",
      "Epoch 11/30 - Loss: 259999.92551041456\n",
      "Epoch 12/30 - Loss: 259979.88021778382\n",
      "Epoch 13/30 - Loss: 259959.8170628374\n",
      "Epoch 14/30 - Loss: 259939.73321508797\n",
      "Epoch 15/30 - Loss: 259919.62584086138\n",
      "Epoch 16/30 - Loss: 259899.49210191038\n",
      "Epoch 17/30 - Loss: 259879.329154015\n",
      "Epoch 18/30 - Loss: 259859.13414559173\n",
      "Epoch 19/30 - Loss: 259838.9042162999\n",
      "Epoch 20/30 - Loss: 259818.63649565898\n",
      "Epoch 21/30 - Loss: 259798.32810165145\n",
      "Epoch 22/30 - Loss: 259777.97613932737\n",
      "Epoch 23/30 - Loss: 259757.57769942182\n",
      "Epoch 24/30 - Loss: 259737.12985695104\n",
      "Epoch 25/30 - Loss: 259716.62966980576\n",
      "Epoch 26/30 - Loss: 259696.07417734858\n",
      "Epoch 27/30 - Loss: 259675.46039900967\n",
      "Epoch 28/30 - Loss: 259654.785332845\n",
      "Epoch 29/30 - Loss: 259634.04595413682\n",
      "Epoch 30/30 - Loss: 259613.23921392692\n",
      "RMSE with bias=False: 4.567182466853837\n",
      "Epoch 1/50 - Loss: 260230.37898948186\n",
      "Epoch 2/50 - Loss: 260209.2383280769\n",
      "Epoch 3/50 - Loss: 260188.12671009797\n",
      "Epoch 4/50 - Loss: 260167.04007688898\n",
      "Epoch 5/50 - Loss: 260145.97439332982\n",
      "Epoch 6/50 - Loss: 260124.9256453944\n",
      "Epoch 7/50 - Loss: 260103.88983769418\n",
      "Epoch 8/50 - Loss: 260082.86299107762\n",
      "Epoch 9/50 - Loss: 260061.84114021994\n",
      "Epoch 10/50 - Loss: 260040.82033126734\n",
      "Epoch 11/50 - Loss: 260019.79661947492\n",
      "Epoch 12/50 - Loss: 259998.76606686975\n",
      "Epoch 13/50 - Loss: 259977.72473993155\n",
      "Epoch 14/50 - Loss: 259956.66870727274\n",
      "Epoch 15/50 - Loss: 259935.59403735778\n",
      "Epoch 16/50 - Loss: 259914.4967962022\n",
      "Epoch 17/50 - Loss: 259893.3730450892\n",
      "Epoch 18/50 - Loss: 259872.21883829703\n",
      "Epoch 19/50 - Loss: 259851.0302208385\n",
      "Epoch 20/50 - Loss: 259829.80322617613\n",
      "Epoch 21/50 - Loss: 259808.53387396713\n",
      "Epoch 22/50 - Loss: 259787.2181677852\n",
      "Epoch 23/50 - Loss: 259765.8520928661\n",
      "Epoch 24/50 - Loss: 259744.43161381813\n",
      "Epoch 25/50 - Loss: 259722.95267235104\n",
      "Epoch 26/50 - Loss: 259701.41118499273\n",
      "Epoch 27/50 - Loss: 259679.8030407901\n",
      "Epoch 28/50 - Loss: 259658.12409900458\n",
      "Epoch 29/50 - Loss: 259636.37018679734\n",
      "Epoch 30/50 - Loss: 259614.5370969066\n",
      "Epoch 31/50 - Loss: 259592.62058529412\n",
      "Epoch 32/50 - Loss: 259570.6163687918\n",
      "Epoch 33/50 - Loss: 259548.52012272476\n",
      "Epoch 34/50 - Loss: 259526.32747851734\n",
      "Epoch 35/50 - Loss: 259504.034021267\n",
      "Epoch 36/50 - Loss: 259481.63528731623\n",
      "Epoch 37/50 - Loss: 259459.12676178582\n",
      "Epoch 38/50 - Loss: 259436.5038760902\n",
      "Epoch 39/50 - Loss: 259413.76200541883\n",
      "Epoch 40/50 - Loss: 259390.8964662018\n",
      "Epoch 41/50 - Loss: 259367.90251353104\n",
      "Epoch 42/50 - Loss: 259344.77533856637\n",
      "Epoch 43/50 - Loss: 259321.51006589635\n",
      "Epoch 44/50 - Loss: 259298.10175087478\n",
      "Epoch 45/50 - Loss: 259274.54537690902\n",
      "Epoch 46/50 - Loss: 259250.83585273262\n",
      "Epoch 47/50 - Loss: 259226.96800961604\n",
      "Epoch 48/50 - Loss: 259202.93659855664\n",
      "Epoch 49/50 - Loss: 259178.73628741602\n",
      "Epoch 50/50 - Loss: 259154.3616580247\n",
      "RMSE with bias=False: 4.563123234820573\n",
      "Epoch 1/20 - Loss: 260149.55495966715\n",
      "Epoch 2/20 - Loss: 260128.17106346507\n",
      "Epoch 3/20 - Loss: 260106.83242984215\n",
      "Epoch 4/20 - Loss: 260085.53489487543\n",
      "Epoch 5/20 - Loss: 260064.27434520482\n",
      "Epoch 6/20 - Loss: 260043.04671515457\n",
      "Epoch 7/20 - Loss: 260021.84798392942\n",
      "Epoch 8/20 - Loss: 260000.67417285705\n",
      "Epoch 9/20 - Loss: 259979.52134270995\n",
      "Epoch 10/20 - Loss: 259958.38559106985\n",
      "Epoch 11/20 - Loss: 259937.2630497577\n",
      "Epoch 12/20 - Loss: 259916.14988230745\n",
      "Epoch 13/20 - Loss: 259895.04228149736\n",
      "Epoch 14/20 - Loss: 259873.9364669186\n",
      "Epoch 15/20 - Loss: 259852.82868260515\n",
      "Epoch 16/20 - Loss: 259831.7151946798\n",
      "Epoch 17/20 - Loss: 259810.59228907185\n",
      "Epoch 18/20 - Loss: 259789.45626924903\n",
      "Epoch 19/20 - Loss: 259768.3034539962\n",
      "Epoch 20/20 - Loss: 259747.13017522544\n",
      "RMSE with bias=False: 4.56836127531037\n",
      "Epoch 1/30 - Loss: 260219.84275550322\n",
      "Epoch 2/30 - Loss: 260199.344836897\n",
      "Epoch 3/30 - Loss: 260178.8740503153\n",
      "Epoch 4/30 - Loss: 260158.42660827152\n",
      "Epoch 5/30 - Loss: 260137.9987591395\n",
      "Epoch 6/30 - Loss: 260117.58678448375\n",
      "Epoch 7/30 - Loss: 260097.18699646523\n",
      "Epoch 8/30 - Loss: 260076.79573528422\n",
      "Epoch 9/30 - Loss: 260056.4093666829\n",
      "Epoch 10/30 - Loss: 260036.02427949174\n",
      "Epoch 11/30 - Loss: 260015.63688322259\n",
      "Epoch 12/30 - Loss: 259995.24360569593\n",
      "Epoch 13/30 - Loss: 259974.84089073\n",
      "Epoch 14/30 - Loss: 259954.4251958315\n",
      "Epoch 15/30 - Loss: 259933.9929899594\n",
      "Epoch 16/30 - Loss: 259913.54075130084\n",
      "Epoch 17/30 - Loss: 259893.06496507663\n",
      "Epoch 18/30 - Loss: 259872.56212138743\n",
      "Epoch 19/30 - Loss: 259852.02871308336\n",
      "Epoch 20/30 - Loss: 259831.4612336485\n",
      "Epoch 21/30 - Loss: 259810.85617512657\n",
      "Epoch 22/30 - Loss: 259790.21002605025\n",
      "Epoch 23/30 - Loss: 259769.51926939553\n",
      "Epoch 24/30 - Loss: 259748.78038057708\n",
      "Epoch 25/30 - Loss: 259727.9898254069\n",
      "Epoch 26/30 - Loss: 259707.14405812512\n",
      "Epoch 27/30 - Loss: 259686.2395194091\n",
      "Epoch 28/30 - Loss: 259665.2726343972\n",
      "Epoch 29/30 - Loss: 259644.23981073938\n",
      "Epoch 30/30 - Loss: 259623.13743663093\n",
      "RMSE with bias=False: 4.567271305159423\n",
      "Epoch 1/50 - Loss: 260161.55640515423\n",
      "Epoch 2/50 - Loss: 260140.9819963237\n",
      "Epoch 3/50 - Loss: 260120.44313443606\n",
      "Epoch 4/50 - Loss: 260099.93616402335\n",
      "Epoch 5/50 - Loss: 260079.45747025698\n",
      "Epoch 6/50 - Loss: 260059.00347646445\n",
      "Epoch 7/50 - Loss: 260038.57064168\n",
      "Epoch 8/50 - Loss: 260018.15545825884\n",
      "Epoch 9/50 - Loss: 259997.75444953766\n",
      "Epoch 10/50 - Loss: 259977.36416754537\n",
      "Epoch 11/50 - Loss: 259956.9811907689\n",
      "Epoch 12/50 - Loss: 259936.60212193866\n",
      "Epoch 13/50 - Loss: 259916.22358588752\n",
      "Epoch 14/50 - Loss: 259895.8422274236\n",
      "Epoch 15/50 - Loss: 259875.45470924792\n",
      "Epoch 16/50 - Loss: 259855.05770991565\n",
      "Epoch 17/50 - Loss: 259834.6479218199\n",
      "Epoch 18/50 - Loss: 259814.2220492111\n",
      "Epoch 19/50 - Loss: 259793.77680624416\n",
      "Epoch 20/50 - Loss: 259773.30891506202\n",
      "Epoch 21/50 - Loss: 259752.81510389087\n",
      "Epoch 22/50 - Loss: 259732.29210516557\n",
      "Epoch 23/50 - Loss: 259711.7366536844\n",
      "Epoch 24/50 - Loss: 259691.14548478174\n",
      "Epoch 25/50 - Loss: 259670.5153325048\n",
      "Epoch 26/50 - Loss: 259649.84292782962\n",
      "Epoch 27/50 - Loss: 259629.12499689026\n",
      "Epoch 28/50 - Loss: 259608.35825920766\n",
      "Epoch 29/50 - Loss: 259587.53942593865\n",
      "Epoch 30/50 - Loss: 259566.66519815652\n",
      "Epoch 31/50 - Loss: 259545.732265103\n",
      "Epoch 32/50 - Loss: 259524.73730248775\n",
      "Epoch 33/50 - Loss: 259503.67697077943\n",
      "Epoch 34/50 - Loss: 259482.5479134929\n",
      "Epoch 35/50 - Loss: 259461.34675550574\n",
      "Epoch 36/50 - Loss: 259440.07010135538\n",
      "Epoch 37/50 - Loss: 259418.7145335552\n",
      "Epoch 38/50 - Loss: 259397.27661090755\n",
      "Epoch 39/50 - Loss: 259375.75286681834\n",
      "Epoch 40/50 - Loss: 259354.13980760358\n",
      "Epoch 41/50 - Loss: 259332.43391080372\n",
      "Epoch 42/50 - Loss: 259310.6316234893\n",
      "Epoch 43/50 - Loss: 259288.72936057736\n",
      "Epoch 44/50 - Loss: 259266.72350310782\n",
      "Epoch 45/50 - Loss: 259244.6103965579\n",
      "Epoch 46/50 - Loss: 259222.38634911884\n",
      "Epoch 47/50 - Loss: 259200.04762997152\n",
      "Epoch 48/50 - Loss: 259177.59046756345\n",
      "Epoch 49/50 - Loss: 259155.01104786334\n",
      "Epoch 50/50 - Loss: 259132.30551260422\n",
      "RMSE with bias=False: 4.562939562485194\n",
      "Epoch 1/20 - Loss: 260127.2301012026\n",
      "Epoch 2/20 - Loss: 260106.1473396042\n",
      "Epoch 3/20 - Loss: 260085.14510660933\n",
      "Epoch 4/20 - Loss: 260064.2184404396\n",
      "Epoch 5/20 - Loss: 260043.36249513706\n",
      "Epoch 6/20 - Loss: 260022.57253512432\n",
      "Epoch 7/20 - Loss: 260001.84392997003\n",
      "Epoch 8/20 - Loss: 259981.1721493374\n",
      "Epoch 9/20 - Loss: 259960.55275811892\n",
      "Epoch 10/20 - Loss: 259939.98141175328\n",
      "Epoch 11/20 - Loss: 259919.45385169543\n",
      "Epoch 12/20 - Loss: 259898.9659010589\n",
      "Epoch 13/20 - Loss: 259878.51346040043\n",
      "Epoch 14/20 - Loss: 259858.09250365937\n",
      "Epoch 15/20 - Loss: 259837.69907422643\n",
      "Epoch 16/20 - Loss: 259817.32928115423\n",
      "Epoch 17/20 - Loss: 259796.97929547972\n",
      "Epoch 18/20 - Loss: 259776.64534669116\n",
      "Epoch 19/20 - Loss: 259756.32371928074\n",
      "Epoch 20/20 - Loss: 259736.0107494334\n",
      "RMSE with bias=False: 4.568267567967885\n",
      "Epoch 1/30 - Loss: 260092.96428626045\n",
      "Epoch 2/30 - Loss: 260072.26475241646\n",
      "Epoch 3/30 - Loss: 260051.6383640446\n",
      "Epoch 4/30 - Loss: 260031.08062306888\n",
      "Epoch 5/30 - Loss: 260010.5871345338\n",
      "Epoch 6/30 - Loss: 259990.15360189756\n",
      "Epoch 7/30 - Loss: 259969.7758224886\n",
      "Epoch 8/30 - Loss: 259949.44968312542\n",
      "Epoch 9/30 - Loss: 259929.17115590474\n",
      "Epoch 10/30 - Loss: 259908.93629413957\n",
      "Epoch 11/30 - Loss: 259888.74122843685\n",
      "Epoch 12/30 - Loss: 259868.58216291392\n",
      "Epoch 13/30 - Loss: 259848.45537154996\n",
      "Epoch 14/30 - Loss: 259828.35719466762\n",
      "Epoch 15/30 - Loss: 259808.28403552232\n",
      "Epoch 16/30 - Loss: 259788.23235702678\n",
      "Epoch 17/30 - Loss: 259768.1986785635\n",
      "Epoch 18/30 - Loss: 259748.17957291804\n",
      "Epoch 19/30 - Loss: 259728.17166331012\n",
      "Epoch 20/30 - Loss: 259708.1716205163\n",
      "Epoch 21/30 - Loss: 259688.1761600886\n",
      "Epoch 22/30 - Loss: 259668.1820396561\n",
      "Epoch 23/30 - Loss: 259648.1860563158\n",
      "Epoch 24/30 - Loss: 259628.18504409696\n",
      "Epoch 25/30 - Loss: 259608.1758715085\n",
      "Epoch 26/30 - Loss: 259588.15543915424\n",
      "Epoch 27/30 - Loss: 259568.120677412\n",
      "Epoch 28/30 - Loss: 259548.06854419017\n",
      "Epoch 29/30 - Loss: 259527.99602274277\n",
      "Epoch 30/30 - Loss: 259507.90011953918\n",
      "RMSE with bias=False: 4.566262167410488\n",
      "Epoch 1/50 - Loss: 260209.3439046688\n",
      "Epoch 2/50 - Loss: 260187.52330899527\n",
      "Epoch 3/50 - Loss: 260165.8045374345\n",
      "Epoch 4/50 - Loss: 260144.18214194133\n",
      "Epoch 5/50 - Loss: 260122.65081027977\n",
      "Epoch 6/50 - Loss: 260101.20535994493\n",
      "Epoch 7/50 - Loss: 260079.8407323176\n",
      "Epoch 8/50 - Loss: 260058.551987049\n",
      "Epoch 9/50 - Loss: 260037.33429662389\n",
      "Epoch 10/50 - Loss: 260016.18294116427\n",
      "Epoch 11/50 - Loss: 259995.09330338883\n",
      "Epoch 12/50 - Loss: 259974.0608637742\n",
      "Epoch 13/50 - Loss: 259953.0811958879\n",
      "Epoch 14/50 - Loss: 259932.14996188277\n",
      "Epoch 15/50 - Loss: 259911.26290815056\n",
      "Epoch 16/50 - Loss: 259890.41586113512\n",
      "Epoch 17/50 - Loss: 259869.60472328757\n",
      "Epoch 18/50 - Loss: 259848.8254691501\n",
      "Epoch 19/50 - Loss: 259828.07414159167\n",
      "Epoch 20/50 - Loss: 259807.3468481512\n",
      "Epoch 21/50 - Loss: 259786.6397575164\n",
      "Epoch 22/50 - Loss: 259765.94909610922\n",
      "Epoch 23/50 - Loss: 259745.27114478173\n",
      "Epoch 24/50 - Loss: 259724.60223562134\n",
      "Epoch 25/50 - Loss: 259703.93874885747\n",
      "Epoch 26/50 - Loss: 259683.2771098495\n",
      "Epoch 27/50 - Loss: 259662.61378619695\n",
      "Epoch 28/50 - Loss: 259641.94528489563\n",
      "Epoch 29/50 - Loss: 259621.26814960773\n",
      "Epoch 30/50 - Loss: 259600.5789580057\n",
      "Epoch 31/50 - Loss: 259579.87431917991\n",
      "Epoch 32/50 - Loss: 259559.15087112348\n",
      "Epoch 33/50 - Loss: 259538.4052782905\n",
      "Epoch 34/50 - Loss: 259517.63422921867\n",
      "Epoch 35/50 - Loss: 259496.83443419484\n",
      "Epoch 36/50 - Loss: 259476.00262301764\n",
      "Epoch 37/50 - Loss: 259455.135542769\n",
      "Epoch 38/50 - Loss: 259434.22995567872\n",
      "Epoch 39/50 - Loss: 259413.2826370083\n",
      "Epoch 40/50 - Loss: 259392.29037300948\n",
      "Epoch 41/50 - Loss: 259371.24995890626\n",
      "Epoch 42/50 - Loss: 259350.1581969209\n",
      "Epoch 43/50 - Loss: 259329.01189436333\n",
      "Epoch 44/50 - Loss: 259307.8078617253\n",
      "Epoch 45/50 - Loss: 259286.54291083402\n",
      "Epoch 46/50 - Loss: 259265.2138530263\n",
      "Epoch 47/50 - Loss: 259243.81749736748\n",
      "Epoch 48/50 - Loss: 259222.3506488804\n",
      "Epoch 49/50 - Loss: 259200.81010682526\n",
      "Epoch 50/50 - Loss: 259179.19266298087\n",
      "RMSE with bias=False: 4.563362734915694\n",
      "Epoch 1/20 - Loss: 260204.13069386902\n",
      "Epoch 2/20 - Loss: 259987.1311201355\n",
      "Epoch 3/20 - Loss: 259766.32158318048\n",
      "Epoch 4/20 - Loss: 259537.78913090896\n",
      "Epoch 5/20 - Loss: 259297.24676408633\n",
      "Epoch 6/20 - Loss: 259039.80778115024\n",
      "Epoch 7/20 - Loss: 258759.72647245694\n",
      "Epoch 8/20 - Loss: 258450.09076726448\n",
      "Epoch 9/20 - Loss: 258102.4516600236\n",
      "Epoch 10/20 - Loss: 257706.3741422513\n",
      "Epoch 11/20 - Loss: 257248.89617294047\n",
      "Epoch 12/20 - Loss: 256713.88804152136\n",
      "Epoch 13/20 - Loss: 256081.31778381887\n",
      "Epoch 14/20 - Loss: 255326.4544925246\n",
      "Epoch 15/20 - Loss: 254419.08808660752\n",
      "Epoch 16/20 - Loss: 253322.92072974535\n",
      "Epoch 17/20 - Loss: 251995.39951351515\n",
      "Epoch 18/20 - Loss: 250388.41004406987\n",
      "Epoch 19/20 - Loss: 248450.4061061839\n",
      "Epoch 20/20 - Loss: 246130.62591146334\n",
      "RMSE with bias=False: 4.430078575766887\n",
      "Epoch 1/30 - Loss: 260152.99900960026\n",
      "Epoch 2/30 - Loss: 259949.64736544233\n",
      "Epoch 3/30 - Loss: 259742.36911969882\n",
      "Epoch 4/30 - Loss: 259527.41886284776\n",
      "Epoch 5/30 - Loss: 259300.64337029587\n",
      "Epoch 6/30 - Loss: 259057.23894049146\n",
      "Epoch 7/30 - Loss: 258791.470154721\n",
      "Epoch 8/30 - Loss: 258496.33501002952\n",
      "Epoch 9/30 - Loss: 258163.16225621552\n",
      "Epoch 10/30 - Loss: 257781.13005320533\n",
      "Epoch 11/30 - Loss: 257336.70334162554\n",
      "Epoch 12/30 - Loss: 256813.00472614315\n",
      "Epoch 13/30 - Loss: 256189.1663667854\n",
      "Epoch 14/30 - Loss: 255439.76644528998\n",
      "Epoch 15/30 - Loss: 254534.54138913585\n",
      "Epoch 16/30 - Loss: 253438.68649075922\n",
      "Epoch 17/30 - Loss: 252114.19575065747\n",
      "Epoch 18/30 - Loss: 250522.78659563922\n",
      "Epoch 19/30 - Loss: 248630.87567335833\n",
      "Epoch 20/30 - Loss: 246416.61399454752\n",
      "Epoch 21/30 - Loss: 243877.96534830373\n",
      "Epoch 22/30 - Loss: 241039.30504289712\n",
      "Epoch 23/30 - Loss: 237952.7418407911\n",
      "Epoch 24/30 - Loss: 234690.72155914598\n",
      "Epoch 25/30 - Loss: 231329.63248253902\n",
      "Epoch 26/30 - Loss: 227929.30860282955\n",
      "Epoch 27/30 - Loss: 224517.0680663377\n",
      "Epoch 28/30 - Loss: 221083.62428586555\n",
      "Epoch 29/30 - Loss: 217592.1186340488\n",
      "Epoch 30/30 - Loss: 213995.16245874763\n",
      "RMSE with bias=False: 4.122453822122104\n",
      "Epoch 1/50 - Loss: 260186.39708663808\n",
      "Epoch 2/50 - Loss: 259975.48671348774\n",
      "Epoch 3/50 - Loss: 259762.8861811734\n",
      "Epoch 4/50 - Loss: 259544.76069283797\n",
      "Epoch 5/50 - Loss: 259317.0186618413\n",
      "Epoch 6/50 - Loss: 259075.07080821582\n",
      "Epoch 7/50 - Loss: 258813.56096226856\n",
      "Epoch 8/50 - Loss: 258526.05276449927\n",
      "Epoch 9/50 - Loss: 258204.65703487542\n",
      "Epoch 10/50 - Loss: 257839.58668361898\n",
      "Epoch 11/50 - Loss: 257418.63170149204\n",
      "Epoch 12/50 - Loss: 256926.5593352129\n",
      "Epoch 13/50 - Loss: 256344.4691610385\n",
      "Epoch 14/50 - Loss: 255649.17661275176\n",
      "Epoch 15/50 - Loss: 254812.77003497866\n",
      "Epoch 16/50 - Loss: 253802.59155569837\n",
      "Epoch 17/50 - Loss: 252582.0252110335\n",
      "Epoch 18/50 - Loss: 251112.6005776599\n",
      "Epoch 19/50 - Loss: 249357.94280725846\n",
      "Epoch 20/50 - Loss: 247289.84913849545\n",
      "Epoch 21/50 - Loss: 244896.0348048965\n",
      "Epoch 22/50 - Loss: 242187.78318257455\n",
      "Epoch 23/50 - Loss: 239204.23088139997\n",
      "Epoch 24/50 - Loss: 236009.42035196238\n",
      "Epoch 25/50 - Loss: 232680.00618568674\n",
      "Epoch 26/50 - Loss: 229285.95088891173\n",
      "Epoch 27/50 - Loss: 225871.438074385\n",
      "Epoch 28/50 - Loss: 222444.58400658926\n",
      "Epoch 29/50 - Loss: 218980.4077496411\n",
      "Epoch 30/50 - Loss: 215434.70142433196\n",
      "Epoch 31/50 - Loss: 211761.9406178437\n",
      "Epoch 32/50 - Loss: 207930.5192987126\n",
      "Epoch 33/50 - Loss: 203931.6704903242\n",
      "Epoch 34/50 - Loss: 199781.5475599742\n",
      "Epoch 35/50 - Loss: 195517.7179439831\n",
      "Epoch 36/50 - Loss: 191192.0027258441\n",
      "Epoch 37/50 - Loss: 186861.79218310816\n",
      "Epoch 38/50 - Loss: 182581.88884574312\n",
      "Epoch 39/50 - Loss: 178398.4770588001\n",
      "Epoch 40/50 - Loss: 174345.98966538202\n",
      "Epoch 41/50 - Loss: 170446.70856641128\n",
      "Epoch 42/50 - Loss: 166712.268879965\n",
      "Epoch 43/50 - Loss: 163146.0379080438\n",
      "Epoch 44/50 - Loss: 159745.53993631646\n",
      "Epoch 45/50 - Loss: 156504.4679556643\n",
      "Epoch 46/50 - Loss: 153414.1544016314\n",
      "Epoch 47/50 - Loss: 150464.56877783433\n",
      "Epoch 48/50 - Loss: 147644.97677033654\n",
      "Epoch 49/50 - Loss: 144944.3847491672\n",
      "Epoch 50/50 - Loss: 142351.85525086476\n",
      "RMSE with bias=False: 3.3596999854152814\n",
      "Epoch 1/20 - Loss: 260180.72725853458\n",
      "Epoch 2/20 - Loss: 259979.32362145063\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregularizations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[72], line 25\u001b[0m, in \u001b[0;36mrun_experiment\u001b[1;34m(learning_rates, regularizations, n_epochs_values, with_bias)\u001b[0m\n\u001b[0;32m     22\u001b[0m item_bias \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_items) \u001b[38;5;28;01mif\u001b[39;00m with_bias \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Chạy SGD\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m user_factors, item_factors, user_bias, item_bias \u001b[38;5;241m=\u001b[39m \u001b[43msgd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mratings_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_factors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_factors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_bias\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Dự đoán kết quả\u001b[39;00m\n\u001b[0;32m     30\u001b[0m predictions \u001b[38;5;241m=\u001b[39m global_bias \u001b[38;5;241m+\u001b[39m user_bias[:, np\u001b[38;5;241m.\u001b[39mnewaxis] \u001b[38;5;241m+\u001b[39m item_bias[np\u001b[38;5;241m.\u001b[39mnewaxis, :] \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(user_factors, item_factors\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;28;01mif\u001b[39;00m with_bias \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdot(user_factors, item_factors\u001b[38;5;241m.\u001b[39mT)\n",
      "Cell \u001b[1;32mIn[70], line 13\u001b[0m, in \u001b[0;36msgd\u001b[1;34m(matrix, user_factors, item_factors, user_bias, item_bias, global_bias, learning_rate, regularization, n_epochs, with_bias)\u001b[0m\n\u001b[0;32m     10\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m global_bias \u001b[38;5;241m+\u001b[39m user_bias[i] \u001b[38;5;241m+\u001b[39m item_bias[j] \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(user_factors[i, :], item_factors[j, :]\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Tính toán dự đoán không có bias\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_factors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_factors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Tính lỗi (error)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m error \u001b[38;5;241m=\u001b[39m matrix[i, j] \u001b[38;5;241m-\u001b[39m prediction\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_experiment(learning_rates, regularizations, n_epochs_values, with_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Loss: 14446.360253983115\n",
      "Epoch 2/50 - Loss: 14400.696068645804\n",
      "Epoch 3/50 - Loss: 14358.090970423718\n",
      "Epoch 4/50 - Loss: 14318.199130403857\n",
      "Epoch 5/50 - Loss: 14280.723013675324\n",
      "Epoch 6/50 - Loss: 14245.405669865751\n",
      "Epoch 7/50 - Loss: 14212.024351424498\n",
      "Epoch 8/50 - Loss: 14180.385222142848\n",
      "Epoch 9/50 - Loss: 14150.318961642093\n",
      "Epoch 10/50 - Loss: 14121.677106866513\n",
      "Epoch 11/50 - Loss: 14094.329000449434\n",
      "Epoch 12/50 - Loss: 14068.159239373412\n",
      "Epoch 13/50 - Loss: 14043.065536584549\n",
      "Epoch 14/50 - Loss: 14018.956923944403\n",
      "Epoch 15/50 - Loss: 13995.752237756358\n",
      "Epoch 16/50 - Loss: 13973.378838611918\n",
      "Epoch 17/50 - Loss: 13951.771525898206\n",
      "Epoch 18/50 - Loss: 13930.871614342712\n",
      "Epoch 19/50 - Loss: 13910.626145729908\n",
      "Epoch 20/50 - Loss: 13890.987213640048\n",
      "Epoch 21/50 - Loss: 13871.911382926226\n",
      "Epoch 22/50 - Loss: 13853.359188816246\n",
      "Epoch 23/50 - Loss: 13835.294703123396\n",
      "Epoch 24/50 - Loss: 13817.68515719167\n",
      "Epoch 25/50 - Loss: 13800.50061294985\n",
      "Epoch 26/50 - Loss: 13783.713674898794\n",
      "Epoch 27/50 - Loss: 13767.299237041361\n",
      "Epoch 28/50 - Loss: 13751.234259748842\n",
      "Epoch 29/50 - Loss: 13735.497572363058\n",
      "Epoch 30/50 - Loss: 13720.069698007172\n",
      "Epoch 31/50 - Loss: 13704.93269762858\n",
      "Epoch 32/50 - Loss: 13690.070030759432\n",
      "Epoch 33/50 - Loss: 13675.466430861296\n",
      "Epoch 34/50 - Loss: 13661.107793438206\n",
      "Epoch 35/50 - Loss: 13646.981075368285\n",
      "Epoch 36/50 - Loss: 13633.074204126779\n",
      "Epoch 37/50 - Loss: 13619.375995756334\n",
      "Epoch 38/50 - Loss: 13605.87608060193\n",
      "Epoch 39/50 - Loss: 13592.564835954317\n",
      "Epoch 40/50 - Loss: 13579.433324861513\n",
      "Epoch 41/50 - Loss: 13566.473240460507\n",
      "Epoch 42/50 - Loss: 13553.676855261952\n",
      "Epoch 43/50 - Loss: 13541.036974889936\n",
      "Epoch 44/50 - Loss: 13528.546895838488\n",
      "Epoch 45/50 - Loss: 13516.200366855\n",
      "Epoch 46/50 - Loss: 13503.991553606542\n",
      "Epoch 47/50 - Loss: 13491.915006323092\n",
      "Epoch 48/50 - Loss: 13479.96563014168\n",
      "Epoch 49/50 - Loss: 13468.13865790884\n",
      "Epoch 50/50 - Loss: 13456.429625220224\n",
      "RMSE with bias=True: 1.0394948842732221\n",
      "Epoch 1/100 - Loss: 14432.933594553453\n",
      "Epoch 2/100 - Loss: 14387.14729516048\n",
      "Epoch 3/100 - Loss: 14344.42763476622\n",
      "Epoch 4/100 - Loss: 14304.428949409017\n",
      "Epoch 5/100 - Loss: 14266.853708615654\n",
      "Epoch 6/100 - Loss: 14231.444845698828\n",
      "Epoch 7/100 - Loss: 14197.979407703557\n",
      "Epoch 8/100 - Loss: 14166.26328903942\n",
      "Epoch 9/100 - Loss: 14136.126855789524\n",
      "Epoch 10/100 - Loss: 14107.421302755378\n",
      "Epoch 11/100 - Loss: 14080.015613940113\n",
      "Epoch 12/100 - Loss: 14053.794020564248\n",
      "Epoch 13/100 - Loss: 14028.653869823094\n",
      "Epoch 14/100 - Loss: 14004.503833213597\n",
      "Epoch 15/100 - Loss: 13981.262396028727\n",
      "Epoch 16/100 - Loss: 13958.856580052088\n",
      "Epoch 17/100 - Loss: 13937.220860034207\n",
      "Epoch 18/100 - Loss: 13916.296241512826\n",
      "Epoch 19/100 - Loss: 13896.029473265831\n",
      "Epoch 20/100 - Loss: 13876.372372369755\n",
      "Epoch 21/100 - Loss: 13857.281243678644\n",
      "Epoch 22/100 - Loss: 13838.716378687253\n",
      "Epoch 23/100 - Loss: 13820.64162132779\n",
      "Epoch 24/100 - Loss: 13803.023990371827\n",
      "Epoch 25/100 - Loss: 13785.833349855136\n",
      "Epoch 26/100 - Loss: 13769.04212037672\n",
      "Epoch 27/100 - Loss: 13752.625025309228\n",
      "Epoch 28/100 - Loss: 13736.558866929357\n",
      "Epoch 29/100 - Loss: 13720.822328285027\n",
      "Epoch 30/100 - Loss: 13705.39579728075\n",
      "Epoch 31/100 - Loss: 13690.261210013849\n",
      "Epoch 32/100 - Loss: 13675.401910851497\n",
      "Epoch 33/100 - Loss: 13660.802527119875\n",
      "Epoch 34/100 - Loss: 13646.448856592906\n",
      "Epoch 35/100 - Loss: 13632.32776623044\n",
      "Epoch 36/100 - Loss: 13618.427100840345\n",
      "Epoch 37/100 - Loss: 13604.735600521773\n",
      "Epoch 38/100 - Loss: 13591.242825903619\n",
      "Epoch 39/100 - Loss: 13577.93909032354\n",
      "Epoch 40/100 - Loss: 13564.815398205943\n",
      "Epoch 41/100 - Loss: 13551.863388987695\n",
      "Epoch 42/100 - Loss: 13539.07528602617\n",
      "Epoch 43/100 - Loss: 13526.443849988182\n",
      "Epoch 44/100 - Loss: 13513.962336279918\n",
      "Epoch 45/100 - Loss: 13501.624456127944\n",
      "Epoch 46/100 - Loss: 13489.424340965568\n",
      "Epoch 47/100 - Loss: 13477.356509815054\n",
      "Epoch 48/100 - Loss: 13465.415839392323\n",
      "Epoch 49/100 - Loss: 13453.597536686568\n",
      "Epoch 50/100 - Loss: 13441.897113793511\n",
      "Epoch 51/100 - Loss: 13430.310364804478\n",
      "Epoch 52/100 - Loss: 13418.833344570805\n",
      "Epoch 53/100 - Loss: 13407.46234918227\n",
      "Epoch 54/100 - Loss: 13396.193898012822\n",
      "Epoch 55/100 - Loss: 13385.024717200118\n",
      "Epoch 56/100 - Loss: 13373.951724438757\n",
      "Epoch 57/100 - Loss: 13362.972014977511\n",
      "Epoch 58/100 - Loss: 13352.082848720103\n",
      "Epoch 59/100 - Loss: 13341.281638338947\n",
      "Epoch 60/100 - Loss: 13330.565938318372\n",
      "Epoch 61/100 - Loss: 13319.93343485204\n",
      "Epoch 62/100 - Loss: 13309.381936523727\n",
      "Epoch 63/100 - Loss: 13298.909365710753\n",
      "Epoch 64/100 - Loss: 13288.513750648319\n",
      "Epoch 65/100 - Loss: 13278.19321810486\n",
      "Epoch 66/100 - Loss: 13267.945986617306\n",
      "Epoch 67/100 - Loss: 13257.770360243085\n",
      "Epoch 68/100 - Loss: 13247.664722786483\n",
      "Epoch 69/100 - Loss: 13237.627532462655\n",
      "Epoch 70/100 - Loss: 13227.657316964087\n",
      "Epoch 71/100 - Loss: 13217.752668899007\n",
      "Epoch 72/100 - Loss: 13207.912241569413\n",
      "Epoch 73/100 - Loss: 13198.134745066507\n",
      "Epoch 74/100 - Loss: 13188.41894265445\n",
      "Epoch 75/100 - Loss: 13178.763647422575\n",
      "Epoch 76/100 - Loss: 13169.167719183897\n",
      "Epoch 77/100 - Loss: 13159.63006160131\n",
      "Epoch 78/100 - Loss: 13150.14961952351\n",
      "Epoch 79/100 - Loss: 13140.725376513954\n",
      "Epoch 80/100 - Loss: 13131.356352559667\n",
      "Epoch 81/100 - Loss: 13122.041601943185\n",
      "Epoch 82/100 - Loss: 13112.780211267876\n",
      "Epoch 83/100 - Loss: 13103.571297623419\n",
      "Epoch 84/100 - Loss: 13094.41400688023\n",
      "Epoch 85/100 - Loss: 13085.30751210477\n",
      "Epoch 86/100 - Loss: 13076.251012084855\n",
      "Epoch 87/100 - Loss: 13067.243729956786\n",
      "Epoch 88/100 - Loss: 13058.284911928558\n",
      "Epoch 89/100 - Loss: 13049.373826087769\n",
      "Epoch 90/100 - Loss: 13040.509761293428\n",
      "Epoch 91/100 - Loss: 13031.692026139566\n",
      "Epoch 92/100 - Loss: 13022.919947990162\n",
      "Epoch 93/100 - Loss: 13014.192872076379\n",
      "Epoch 94/100 - Loss: 13005.510160654165\n",
      "Epoch 95/100 - Loss: 12996.871192215898\n",
      "Epoch 96/100 - Loss: 12988.275360753229\n",
      "Epoch 97/100 - Loss: 12979.722075066302\n",
      "Epoch 98/100 - Loss: 12971.210758117735\n",
      "Epoch 99/100 - Loss: 12962.740846425657\n",
      "Epoch 100/100 - Loss: 12954.311789495045\n",
      "RMSE with bias=True: 1.0199715627969863\n",
      "Epoch 1/50 - Loss: 14429.969692220846\n",
      "Epoch 2/50 - Loss: 14384.357594952731\n",
      "Epoch 3/50 - Loss: 14341.844894289792\n",
      "Epoch 4/50 - Loss: 14302.074285183695\n",
      "Epoch 5/50 - Loss: 14264.739599079576\n",
      "Epoch 6/50 - Loss: 14229.577404214282\n",
      "Epoch 7/50 - Loss: 14196.360098771527\n",
      "Epoch 8/50 - Loss: 14164.89022083005\n",
      "Epoch 9/50 - Loss: 14134.995751048202\n",
      "Epoch 10/50 - Loss: 14106.52622615315\n",
      "Epoch 11/50 - Loss: 14079.349515435892\n",
      "Epoch 12/50 - Loss: 14053.349140110726\n",
      "Epoch 13/50 - Loss: 14028.422037820355\n",
      "Epoch 14/50 - Loss: 14004.47669274618\n",
      "Epoch 15/50 - Loss: 13981.431566528434\n",
      "Epoch 16/50 - Loss: 13959.21377716729\n",
      "Epoch 17/50 - Loss: 13937.757982785552\n",
      "Epoch 18/50 - Loss: 13917.005435023179\n",
      "Epoch 19/50 - Loss: 13896.903173241952\n",
      "Epoch 20/50 - Loss: 13877.403335931169\n",
      "Epoch 21/50 - Loss: 13858.462569940682\n",
      "Epoch 22/50 - Loss: 13840.04152162489\n",
      "Epoch 23/50 - Loss: 13822.104396789458\n",
      "Epoch 24/50 - Loss: 13804.618578629255\n",
      "Epoch 25/50 - Loss: 13787.554294717998\n",
      "Epoch 26/50 - Loss: 13770.884325642108\n",
      "Epoch 27/50 - Loss: 13754.583749122516\n",
      "Epoch 28/50 - Loss: 13738.62971449917\n",
      "Epoch 29/50 - Loss: 13723.001243291461\n",
      "Epoch 30/50 - Loss: 13707.679052244577\n",
      "Epoch 31/50 - Loss: 13692.645395842595\n",
      "Epoch 32/50 - Loss: 13677.883925737988\n",
      "Epoch 33/50 - Loss: 13663.379564942472\n",
      "Epoch 34/50 - Loss: 13649.11839494267\n",
      "Epoch 35/50 - Loss: 13635.087554176294\n",
      "Epoch 36/50 - Loss: 13621.27514652901\n",
      "Epoch 37/50 - Loss: 13607.67015869692\n",
      "Epoch 38/50 - Loss: 13594.262385422799\n",
      "Epoch 39/50 - Loss: 13581.042361739694\n",
      "Epoch 40/50 - Loss: 13568.0013014741\n",
      "Epoch 41/50 - Loss: 13555.131041351968\n",
      "Epoch 42/50 - Loss: 13542.423990132631\n",
      "Epoch 43/50 - Loss: 13529.873082265849\n",
      "Epoch 44/50 - Loss: 13517.471735624467\n",
      "Epoch 45/50 - Loss: 13505.213812919272\n",
      "Epoch 46/50 - Loss: 13493.093586442326\n",
      "Epoch 47/50 - Loss: 13481.10570582794\n",
      "Epoch 48/50 - Loss: 13469.245168550337\n",
      "Epoch 49/50 - Loss: 13457.507292908977\n",
      "Epoch 50/50 - Loss: 13445.887693274539\n",
      "RMSE with bias=True: 1.0390923193471688\n",
      "Epoch 1/100 - Loss: 14447.585870479597\n",
      "Epoch 2/100 - Loss: 14401.639618754387\n",
      "Epoch 3/100 - Loss: 14358.814418461016\n",
      "Epoch 4/100 - Loss: 14318.75117014633\n",
      "Epoch 5/100 - Loss: 14281.142075287833\n",
      "Epoch 6/100 - Loss: 14245.722220014342\n",
      "Epoch 7/100 - Loss: 14212.262653542452\n",
      "Epoch 8/100 - Loss: 14180.56468503419\n",
      "Epoch 9/100 - Loss: 14150.455174616749\n",
      "Epoch 10/100 - Loss: 14121.78263646188\n",
      "Epoch 11/100 - Loss: 14094.41400597169\n",
      "Epoch 12/100 - Loss: 14068.23195080406\n",
      "Epoch 13/100 - Loss: 14043.132627900794\n",
      "Epoch 14/100 - Loss: 14019.023806882173\n",
      "Epoch 15/100 - Loss: 13995.82329492686\n",
      "Epoch 16/100 - Loss: 13973.45761022947\n",
      "Epoch 17/100 - Loss: 13951.860860855824\n",
      "Epoch 18/100 - Loss: 13930.97379370373\n",
      "Epoch 19/100 - Loss: 13910.742984700397\n",
      "Epoch 20/100 - Loss: 13891.120146578955\n",
      "Epoch 21/100 - Loss: 13872.061534825734\n",
      "Epoch 22/100 - Loss: 13853.527435842161\n",
      "Epoch 23/100 - Loss: 13835.48172418584\n",
      "Epoch 24/100 - Loss: 13817.891478049556\n",
      "Epoch 25/100 - Loss: 13800.726644015624\n",
      "Epoch 26/100 - Loss: 13783.95974365533\n",
      "Epoch 27/100 - Loss: 13767.565615799616\n",
      "Epoch 28/100 - Loss: 13751.521189335199\n",
      "Epoch 29/100 - Loss: 13735.80528222722\n",
      "Epoch 30/100 - Loss: 13720.398423162656\n",
      "Epoch 31/100 - Loss: 13705.282692781928\n",
      "Epoch 32/100 - Loss: 13690.441581940373\n",
      "Epoch 33/100 - Loss: 13675.859864830183\n",
      "Epoch 34/100 - Loss: 13661.523485119817\n",
      "Epoch 35/100 - Loss: 13647.41945353825\n",
      "Epoch 36/100 - Loss: 13633.535755554814\n",
      "Epoch 37/100 - Loss: 13619.861267995679\n",
      "Epoch 38/100 - Loss: 13606.385683595343\n",
      "Epoch 39/100 - Loss: 13593.099442615288\n",
      "Epoch 40/100 - Loss: 13579.993670773061\n",
      "Epoch 41/100 - Loss: 13567.060122822955\n",
      "Epoch 42/100 - Loss: 13554.291131209038\n",
      "Epoch 43/100 - Loss: 13541.679559279886\n",
      "Epoch 44/100 - Loss: 13529.21875861735\n",
      "Epoch 45/100 - Loss: 13516.902530079258\n",
      "Epoch 46/100 - Loss: 13504.725088202287\n",
      "Epoch 47/100 - Loss: 13492.681028649575\n",
      "Epoch 48/100 - Loss: 13480.765298422039\n",
      "Epoch 49/100 - Loss: 13468.973168578957\n",
      "Epoch 50/100 - Loss: 13457.30020924211\n",
      "Epoch 51/100 - Loss: 13445.742266679465\n",
      "Epoch 52/100 - Loss: 13434.295442284134\n",
      "Epoch 53/100 - Loss: 13422.956073282141\n",
      "Epoch 54/100 - Loss: 13411.720715018644\n",
      "Epoch 55/100 - Loss: 13400.586124686755\n",
      "Epoch 56/100 - Loss: 13389.549246375\n",
      "Epoch 57/100 - Loss: 13378.607197320955\n",
      "Epoch 58/100 - Loss: 13367.757255268956\n",
      "Epoch 59/100 - Loss: 13356.996846839147\n",
      "Epoch 60/100 - Loss: 13346.32353682242\n",
      "Epoch 61/100 - Loss: 13335.735018324664\n",
      "Epoch 62/100 - Loss: 13325.229103689766\n",
      "Epoch 63/100 - Loss: 13314.803716135759\n",
      "Epoch 64/100 - Loss: 13304.456882047114\n",
      "Epoch 65/100 - Loss: 13294.186723867213\n",
      "Epoch 66/100 - Loss: 13283.99145354401\n",
      "Epoch 67/100 - Loss: 13273.869366481802\n",
      "Epoch 68/100 - Loss: 13263.818835959024\n",
      "Epoch 69/100 - Loss: 13253.83830797389\n",
      "Epoch 70/100 - Loss: 13243.926296483067\n",
      "Epoch 71/100 - Loss: 13234.081379002599\n",
      "Epoch 72/100 - Loss: 13224.302192539908\n",
      "Epoch 73/100 - Loss: 13214.58742983307\n",
      "Epoch 74/100 - Loss: 13204.935835870212\n",
      "Epoch 75/100 - Loss: 13195.346204668727\n",
      "Epoch 76/100 - Loss: 13185.817376291083\n",
      "Epoch 77/100 - Loss: 13176.348234082285\n",
      "Epoch 78/100 - Loss: 13166.93770210701\n",
      "Epoch 79/100 - Loss: 13157.584742773977\n",
      "Epoch 80/100 - Loss: 13148.28835463207\n",
      "Epoch 81/100 - Loss: 13139.0475703231\n",
      "Epoch 82/100 - Loss: 13129.861454681342\n",
      "Epoch 83/100 - Loss: 13120.729102966296\n",
      "Epoch 84/100 - Loss: 13111.64963922055\n",
      "Epoch 85/100 - Loss: 13102.622214740688\n",
      "Epoch 86/100 - Loss: 13093.646006654151\n",
      "Epoch 87/100 - Loss: 13084.720216593283\n",
      "Epoch 88/100 - Loss: 13075.84406945998\n",
      "Epoch 89/100 - Loss: 13067.016812271646\n",
      "Epoch 90/100 - Loss: 13058.237713085886\n",
      "Epoch 91/100 - Loss: 13049.506059994952\n",
      "Epoch 92/100 - Loss: 13040.821160185691\n",
      "Epoch 93/100 - Loss: 13032.182339061044\n",
      "Epoch 94/100 - Loss: 13023.588939416892\n",
      "Epoch 95/100 - Loss: 13015.040320671133\n",
      "Epoch 96/100 - Loss: 13006.535858141257\n",
      "Epoch 97/100 - Loss: 12998.074942365865\n",
      "Epoch 98/100 - Loss: 12989.65697846853\n",
      "Epoch 99/100 - Loss: 12981.281385558932\n",
      "Epoch 100/100 - Loss: 12972.947596170421\n",
      "RMSE with bias=True: 1.02071081985618\n",
      "Epoch 1/50 - Loss: 14445.50887644127\n",
      "Epoch 2/50 - Loss: 14399.647142204762\n",
      "Epoch 3/50 - Loss: 14356.947206743685\n",
      "Epoch 4/50 - Loss: 14317.03589841247\n",
      "Epoch 5/50 - Loss: 14279.59509375895\n",
      "Epoch 6/50 - Loss: 14244.35235552416\n",
      "Epoch 7/50 - Loss: 14211.073298657282\n",
      "Epoch 8/50 - Loss: 14179.55535186005\n",
      "Epoch 9/50 - Loss: 14149.622647412123\n",
      "Epoch 10/50 - Loss: 14121.121824354143\n",
      "Epoch 11/50 - Loss: 14093.91857207798\n",
      "Epoch 12/50 - Loss: 14067.894775057997\n",
      "Epoch 13/50 - Loss: 14042.94614649271\n",
      "Epoch 14/50 - Loss: 14018.980260340271\n",
      "Epoch 15/50 - Loss: 13995.914908665418\n",
      "Epoch 16/50 - Loss: 13973.676725238312\n",
      "Epoch 17/50 - Loss: 13952.200027590903\n",
      "Epoch 18/50 - Loss: 13931.425838806335\n",
      "Epoch 19/50 - Loss: 13911.301057617127\n",
      "Epoch 20/50 - Loss: 13891.777751267957\n",
      "Epoch 21/50 - Loss: 13872.812550341563\n",
      "Epoch 22/50 - Loss: 13854.36612857638\n",
      "Epoch 23/50 - Loss: 13836.402753792583\n",
      "Epoch 24/50 - Loss: 13818.889898547804\n",
      "Epoch 25/50 - Loss: 13801.797901169492\n",
      "Epoch 26/50 - Loss: 13785.099669452113\n",
      "Epoch 27/50 - Loss: 13768.770420644727\n",
      "Epoch 28/50 - Loss: 13752.787452439408\n",
      "Epoch 29/50 - Loss: 13737.129940557908\n",
      "Epoch 30/50 - Loss: 13721.778759256242\n",
      "Epoch 31/50 - Loss: 13706.716321663665\n",
      "Epoch 32/50 - Loss: 13691.926437354714\n",
      "Epoch 33/50 - Loss: 13677.394184957635\n",
      "Epoch 34/50 - Loss: 13663.105797933884\n",
      "Epoch 35/50 - Loss: 13649.048561934726\n",
      "Epoch 36/50 - Loss: 13635.210722373173\n",
      "Epoch 37/50 - Loss: 13621.581401037849\n",
      "Epoch 38/50 - Loss: 13608.150520734987\n",
      "Epoch 39/50 - Loss: 13594.908737080126\n",
      "Epoch 40/50 - Loss: 13581.84737667378\n",
      "Epoch 41/50 - Loss: 13568.95838099045\n",
      "Epoch 42/50 - Loss: 13556.234255394227\n",
      "Epoch 43/50 - Loss: 13543.668022763797\n",
      "Epoch 44/50 - Loss: 13531.253181266953\n",
      "Epoch 45/50 - Loss: 13518.983665882015\n",
      "Epoch 46/50 - Loss: 13506.853813301963\n",
      "Epoch 47/50 - Loss: 13494.858329902758\n",
      "Epoch 48/50 - Loss: 13482.992262486618\n",
      "Epoch 49/50 - Loss: 13471.250971541791\n",
      "Epoch 50/50 - Loss: 13459.630106789644\n",
      "RMSE with bias=True: 1.039626881841908\n",
      "Epoch 1/100 - Loss: 14431.991001718172\n",
      "Epoch 2/100 - Loss: 14386.282350825888\n",
      "Epoch 3/100 - Loss: 14343.735321227303\n",
      "Epoch 4/100 - Loss: 14303.975877612846\n",
      "Epoch 5/100 - Loss: 14266.685238068165\n",
      "Epoch 6/100 - Loss: 14231.59047100549\n",
      "Epoch 7/100 - Loss: 14198.4568279957\n",
      "Epoch 8/100 - Loss: 14167.08147851929\n",
      "Epoch 9/100 - Loss: 14137.288378180241\n",
      "Epoch 10/100 - Loss: 14108.924054470683\n",
      "Epoch 11/100 - Loss: 14081.854136340728\n",
      "Epoch 12/100 - Loss: 14055.960487658469\n",
      "Epoch 13/100 - Loss: 14031.13883180505\n",
      "Epoch 14/100 - Loss: 14007.29677646004\n",
      "Epoch 15/100 - Loss: 13984.352165153188\n",
      "Epoch 16/100 - Loss: 13962.23169623955\n",
      "Epoch 17/100 - Loss: 13940.869761280463\n",
      "Epoch 18/100 - Loss: 13920.207463920498\n",
      "Epoch 19/100 - Loss: 13900.191787688133\n",
      "Epoch 20/100 - Loss: 13880.77488705525\n",
      "Epoch 21/100 - Loss: 13861.913480859574\n",
      "Epoch 22/100 - Loss: 13843.568331035294\n",
      "Epoch 23/100 - Loss: 13825.703792709935\n",
      "Epoch 24/100 - Loss: 13808.28742423421\n",
      "Epoch 25/100 - Loss: 13791.289647751526\n",
      "Epoch 26/100 - Loss: 13774.683452562676\n",
      "Epoch 27/100 - Loss: 13758.444134882373\n",
      "Epoch 28/100 - Loss: 13742.549068678498\n",
      "Epoch 29/100 - Loss: 13726.977503172715\n",
      "Epoch 30/100 - Loss: 13711.71038330866\n",
      "Epoch 31/100 - Loss: 13696.730190091632\n",
      "Epoch 32/100 - Loss: 13682.02079819224\n",
      "Epoch 33/100 - Loss: 13667.567348607174\n",
      "Epoch 34/100 - Loss: 13653.356134507563\n",
      "Epoch 35/100 - Loss: 13639.374498675752\n",
      "Epoch 36/100 - Loss: 13625.61074116591\n",
      "Epoch 37/100 - Loss: 13612.054036011059\n",
      "Epoch 38/100 - Loss: 13598.694355961956\n",
      "Epoch 39/100 - Loss: 13585.52240437607\n",
      "Epoch 40/100 - Loss: 13572.529553490062\n",
      "Epoch 41/100 - Loss: 13559.707788405869\n",
      "Epoch 42/100 - Loss: 13547.049656199633\n",
      "Epoch 43/100 - Loss: 13534.548219638138\n",
      "Epoch 44/100 - Loss: 13522.197015042379\n",
      "Epoch 45/100 - Loss: 13509.990013893594\n",
      "Epoch 46/100 - Loss: 13497.921587819937\n",
      "Epoch 47/100 - Loss: 13485.986476642329\n",
      "Epoch 48/100 - Loss: 13474.179759192632\n",
      "Epoch 49/100 - Loss: 13462.496826645138\n",
      "Epoch 50/100 - Loss: 13450.933358131055\n",
      "Epoch 51/100 - Loss: 13439.485298426975\n",
      "Epoch 52/100 - Loss: 13428.148837531848\n",
      "Epoch 53/100 - Loss: 13416.920391960339\n",
      "Epoch 54/100 - Loss: 13405.796587602232\n",
      "Epoch 55/100 - Loss: 13394.774244008378\n",
      "Epoch 56/100 - Loss: 13383.850359977738\n",
      "Epoch 57/100 - Loss: 13373.022100332288\n",
      "Epoch 58/100 - Loss: 13362.286783775535\n",
      "Epoch 59/100 - Loss: 13351.641871743268\n",
      "Epoch 60/100 - Loss: 13341.084958157613\n",
      "Epoch 61/100 - Loss: 13330.613760009903\n",
      "Epoch 62/100 - Loss: 13320.226108700515\n",
      "Epoch 63/100 - Loss: 13309.919942071143\n",
      "Epoch 64/100 - Loss: 13299.69329707047\n",
      "Epoch 65/100 - Loss: 13289.544303001407\n",
      "Epoch 66/100 - Loss: 13279.471175298822\n",
      "Epoch 67/100 - Loss: 13269.472209794896\n",
      "Epoch 68/100 - Loss: 13259.545777430914\n",
      "Epoch 69/100 - Loss: 13249.690319377492\n",
      "Epoch 70/100 - Loss: 13239.904342530957\n",
      "Epoch 71/100 - Loss: 13230.186415353359\n",
      "Epoch 72/100 - Loss: 13220.535164028279\n",
      "Epoch 73/100 - Loss: 13210.949268907285\n",
      "Epoch 74/100 - Loss: 13201.427461221516\n",
      "Epoch 75/100 - Loss: 13191.968520038532\n",
      "Epoch 76/100 - Loss: 13182.571269443022\n",
      "Epoch 77/100 - Loss: 13173.234575925608\n",
      "Epoch 78/100 - Loss: 13163.957345959137\n",
      "Epoch 79/100 - Loss: 13154.738523751434\n",
      "Epoch 80/100 - Loss: 13145.577089157894\n",
      "Epoch 81/100 - Loss: 13136.472055741617\n",
      "Epoch 82/100 - Loss: 13127.422468971165\n",
      "Epoch 83/100 - Loss: 13118.427404541299\n",
      "Epoch 84/100 - Loss: 13109.485966811575\n",
      "Epoch 85/100 - Loss: 13100.597287350034\n",
      "Epoch 86/100 - Loss: 13091.760523576033\n",
      "Epoch 87/100 - Loss: 13082.974857492783\n",
      "Epoch 88/100 - Loss: 13074.239494504884\n",
      "Epoch 89/100 - Loss: 13065.553662311393\n",
      "Epoch 90/100 - Loss: 13056.916609872356\n",
      "Epoch 91/100 - Loss: 13048.327606439592\n",
      "Epoch 92/100 - Loss: 13039.785940649537\n",
      "Epoch 93/100 - Loss: 13031.290919672572\n",
      "Epoch 94/100 - Loss: 13022.841868414058\n",
      "Epoch 95/100 - Loss: 13014.438128764623\n",
      "Epoch 96/100 - Loss: 13006.079058894968\n",
      "Epoch 97/100 - Loss: 12997.764032592228\n",
      "Epoch 98/100 - Loss: 12989.49243863585\n",
      "Epoch 99/100 - Loss: 12981.263680208122\n",
      "Epoch 100/100 - Loss: 12973.077174339302\n",
      "RMSE with bias=True: 1.0207239146398894\n",
      "Epoch 1/50 - Loss: 14302.23506253167\n",
      "Epoch 2/50 - Loss: 14020.228090402252\n",
      "Epoch 3/50 - Loss: 13826.17233643312\n",
      "Epoch 4/50 - Loss: 13672.654818035391\n",
      "Epoch 5/50 - Loss: 13541.543504842266\n",
      "Epoch 6/50 - Loss: 13424.548991897493\n",
      "Epoch 7/50 - Loss: 13317.45067621633\n",
      "Epoch 8/50 - Loss: 13217.886797563207\n",
      "Epoch 9/50 - Loss: 13124.401815607518\n",
      "Epoch 10/50 - Loss: 13036.012117418875\n",
      "Epoch 11/50 - Loss: 12951.999535618665\n",
      "Epoch 12/50 - Loss: 12871.808346333813\n",
      "Epoch 13/50 - Loss: 12794.990678665235\n",
      "Epoch 14/50 - Loss: 12721.175424894336\n",
      "Epoch 15/50 - Loss: 12650.049127334787\n",
      "Epoch 16/50 - Loss: 12581.34334895966\n",
      "Epoch 17/50 - Loss: 12514.82580187907\n",
      "Epoch 18/50 - Loss: 12450.293809423616\n",
      "Epoch 19/50 - Loss: 12387.569311419224\n",
      "Epoch 20/50 - Loss: 12326.494945010214\n",
      "Epoch 21/50 - Loss: 12266.930906835087\n",
      "Epoch 22/50 - Loss: 12208.752401236688\n",
      "Epoch 23/50 - Loss: 12151.847538971126\n",
      "Epoch 24/50 - Loss: 12096.115589003475\n",
      "Epoch 25/50 - Loss: 12041.465511430857\n",
      "Epoch 26/50 - Loss: 11987.814717180749\n",
      "Epoch 27/50 - Loss: 11935.088012698201\n",
      "Epoch 28/50 - Loss: 11883.216696991058\n",
      "Epoch 29/50 - Loss: 11832.137785222127\n",
      "Epoch 30/50 - Loss: 11781.793338192385\n",
      "Epoch 31/50 - Loss: 11732.129881015506\n",
      "Epoch 32/50 - Loss: 11683.097897362319\n",
      "Epoch 33/50 - Loss: 11634.651388072429\n",
      "Epoch 34/50 - Loss: 11586.747484858226\n",
      "Epoch 35/50 - Loss: 11539.34611137553\n",
      "Epoch 36/50 - Loss: 11492.409685188197\n",
      "Epoch 37/50 - Loss: 11445.90285518273\n",
      "Epoch 38/50 - Loss: 11399.792269835003\n",
      "Epoch 39/50 - Loss: 11354.04637243338\n",
      "Epoch 40/50 - Loss: 11308.635219949132\n",
      "Epoch 41/50 - Loss: 11263.530322737517\n",
      "Epoch 42/50 - Loss: 11218.7045026682\n",
      "Epoch 43/50 - Loss: 11174.13176763666\n",
      "Epoch 44/50 - Loss: 11129.787200707968\n",
      "Epoch 45/50 - Loss: 11085.646862399512\n",
      "Epoch 46/50 - Loss: 11041.687704829332\n",
      "Epoch 47/50 - Loss: 10997.887496645842\n",
      "Epoch 48/50 - Loss: 10954.22475781358\n",
      "Epoch 49/50 - Loss: 10910.67870347175\n",
      "Epoch 50/50 - Loss: 10867.229196200837\n",
      "RMSE with bias=True: 0.9324465622200897\n",
      "Epoch 1/100 - Loss: 14310.340285295366\n",
      "Epoch 2/100 - Loss: 14027.404669838825\n",
      "Epoch 3/100 - Loss: 13832.454588858898\n",
      "Epoch 4/100 - Loss: 13678.008698213487\n",
      "Epoch 5/100 - Loss: 13545.962974730219\n",
      "Epoch 6/100 - Loss: 13428.051340994134\n",
      "Epoch 7/100 - Loss: 13320.066568140233\n",
      "Epoch 8/100 - Loss: 13219.653647048555\n",
      "Epoch 9/100 - Loss: 13125.359820381862\n",
      "Epoch 10/100 - Loss: 13036.20192606423\n",
      "Epoch 11/100 - Loss: 12951.460902877363\n",
      "Epoch 12/100 - Loss: 12870.57939164852\n",
      "Epoch 13/100 - Loss: 12793.107517300501\n",
      "Epoch 14/100 - Loss: 12718.672029738465\n",
      "Epoch 15/100 - Loss: 12646.957332235892\n",
      "Epoch 16/100 - Loss: 12577.692936796868\n",
      "Epoch 17/100 - Loss: 12510.644640931627\n",
      "Epoch 18/100 - Loss: 12445.608014674388\n",
      "Epoch 19/100 - Loss: 12382.403415943949\n",
      "Epoch 20/100 - Loss: 12320.872072192198\n",
      "Epoch 21/100 - Loss: 12260.872937819076\n",
      "Epoch 22/100 - Loss: 12202.280134444478\n",
      "Epoch 23/100 - Loss: 12144.980840064303\n",
      "Epoch 24/100 - Loss: 12088.873530675786\n",
      "Epoch 25/100 - Loss: 12033.86650302769\n",
      "Epoch 26/100 - Loss: 11979.876624511076\n",
      "Epoch 27/100 - Loss: 11926.828268597092\n",
      "Epoch 28/100 - Loss: 11874.652403278944\n",
      "Epoch 29/100 - Loss: 11823.285806722826\n",
      "Epoch 30/100 - Loss: 11772.670389442763\n",
      "Epoch 31/100 - Loss: 11722.7526062459\n",
      "Epoch 32/100 - Loss: 11673.482944253374\n",
      "Epoch 33/100 - Loss: 11624.815475718904\n",
      "Epoch 34/100 - Loss: 11576.707466287504\n",
      "Epoch 35/100 - Loss: 11529.119030887683\n",
      "Epoch 36/100 - Loss: 11482.012830703208\n",
      "Epoch 37/100 - Loss: 11435.353805705558\n",
      "Epoch 38/100 - Loss: 11389.108938072\n",
      "Epoch 39/100 - Loss: 11343.24704252314\n",
      "Epoch 40/100 - Loss: 11297.7385801997\n",
      "Epoch 41/100 - Loss: 11252.555493197642\n",
      "Epoch 42/100 - Loss: 11207.671057293272\n",
      "Epoch 43/100 - Loss: 11163.059750748494\n",
      "Epoch 44/100 - Loss: 11118.697137387742\n",
      "Epoch 45/100 - Loss: 11074.559762393612\n",
      "Epoch 46/100 - Loss: 11030.625059494147\n",
      "Epoch 47/100 - Loss: 10986.87126840125\n",
      "Epoch 48/100 - Loss: 10943.2773615274\n",
      "Epoch 49/100 - Loss: 10899.82297914935\n",
      "Epoch 50/100 - Loss: 10856.488372310818\n",
      "Epoch 51/100 - Loss: 10813.254352864216\n",
      "Epoch 52/100 - Loss: 10770.102250146014\n",
      "Epoch 53/100 - Loss: 10727.013873858865\n",
      "Epoch 54/100 - Loss: 10683.971482807114\n",
      "Epoch 55/100 - Loss: 10640.957759192126\n",
      "Epoch 56/100 - Loss: 10597.955788226236\n",
      "Epoch 57/100 - Loss: 10554.949042868575\n",
      "Epoch 58/100 - Loss: 10511.921373525895\n",
      "Epoch 59/100 - Loss: 10468.857002588335\n",
      "Epoch 60/100 - Loss: 10425.740523698436\n",
      "Epoch 61/100 - Loss: 10382.55690566691\n",
      "Epoch 62/100 - Loss: 10339.2915009621\n",
      "Epoch 63/100 - Loss: 10295.93005870516\n",
      "Epoch 64/100 - Loss: 10252.458742102535\n",
      "Epoch 65/100 - Loss: 10208.86415024134\n",
      "Epoch 66/100 - Loss: 10165.133344159363\n",
      "Epoch 67/100 - Loss: 10121.253877081897\n",
      "Epoch 68/100 - Loss: 10077.213828692598\n",
      "Epoch 69/100 - Loss: 10033.001843270611\n",
      "Epoch 70/100 - Loss: 9988.607171490681\n",
      "Epoch 71/100 - Loss: 9944.019715632241\n",
      "Epoch 72/100 - Loss: 9899.230077896233\n",
      "Epoch 73/100 - Loss: 9854.22961146639\n",
      "Epoch 74/100 - Loss: 9809.010473892258\n",
      "Epoch 75/100 - Loss: 9763.56568229898\n",
      "Epoch 76/100 - Loss: 9717.889169862401\n",
      "Epoch 77/100 - Loss: 9671.975842908898\n",
      "Epoch 78/100 - Loss: 9625.821637928826\n",
      "Epoch 79/100 - Loss: 9579.42357771612\n",
      "Epoch 80/100 - Loss: 9532.77982577593\n",
      "Epoch 81/100 - Loss: 9485.889738076707\n",
      "Epoch 82/100 - Loss: 9438.75391116585\n",
      "Epoch 83/100 - Loss: 9391.374225617259\n",
      "Epoch 84/100 - Loss: 9343.753883748808\n",
      "Epoch 85/100 - Loss: 9295.897440526469\n",
      "Epoch 86/100 - Loss: 9247.810826574372\n",
      "Epoch 87/100 - Loss: 9199.501362231827\n",
      "Epoch 88/100 - Loss: 9150.977761645649\n",
      "Epoch 89/100 - Loss: 9102.250125959643\n",
      "Epoch 90/100 - Loss: 9053.329924762473\n",
      "Epoch 91/100 - Loss: 9004.229965086777\n",
      "Epoch 92/100 - Loss: 8954.964347406874\n",
      "Epoch 93/100 - Loss: 8905.548408271074\n",
      "Epoch 94/100 - Loss: 8855.99864941178\n",
      "Epoch 95/100 - Loss: 8806.332653410085\n",
      "Epoch 96/100 - Loss: 8756.568986241984\n",
      "Epoch 97/100 - Loss: 8706.727087296\n",
      "Epoch 98/100 - Loss: 8656.82714771836\n",
      "Epoch 99/100 - Loss: 8606.88997821254\n",
      "Epoch 100/100 - Loss: 8556.936867675664\n",
      "RMSE with bias=True: 0.826746557601737\n",
      "Epoch 1/50 - Loss: 14307.98450440141\n",
      "Epoch 2/50 - Loss: 14027.370523923486\n",
      "Epoch 3/50 - Loss: 13833.550476796012\n",
      "Epoch 4/50 - Loss: 13679.70398341848\n",
      "Epoch 5/50 - Loss: 13548.10404462497\n",
      "Epoch 6/50 - Loss: 13430.668113024767\n",
      "Epoch 7/50 - Loss: 13323.264386331288\n",
      "Epoch 8/50 - Loss: 13223.555038749331\n",
      "Epoch 9/50 - Loss: 13130.077938705537\n",
      "Epoch 10/50 - Loss: 13041.831858094118\n",
      "Epoch 11/50 - Loss: 12958.079492736371\n",
      "Epoch 12/50 - Loss: 12878.24828521894\n",
      "Epoch 13/50 - Loss: 12801.876867195035\n",
      "Epoch 14/50 - Loss: 12728.58382420522\n",
      "Epoch 15/50 - Loss: 12658.048052406046\n",
      "Epoch 16/50 - Loss: 12589.995557715933\n",
      "Epoch 17/50 - Loss: 12524.190094373918\n",
      "Epoch 18/50 - Loss: 12460.42624473808\n",
      "Epoch 19/50 - Loss: 12398.524139426256\n",
      "Epoch 20/50 - Loss: 12338.325329832287\n",
      "Epoch 21/50 - Loss: 12279.68949912507\n",
      "Epoch 22/50 - Loss: 12222.491800519545\n",
      "Epoch 23/50 - Loss: 12166.620675466083\n",
      "Epoch 24/50 - Loss: 12111.97604592329\n",
      "Epoch 25/50 - Loss: 12058.467802851877\n",
      "Epoch 26/50 - Loss: 12006.014532486253\n",
      "Epoch 27/50 - Loss: 11954.542435727968\n",
      "Epoch 28/50 - Loss: 11903.984406010883\n",
      "Epoch 29/50 - Loss: 11854.279238371084\n",
      "Epoch 30/50 - Loss: 11805.370947993837\n",
      "Epoch 31/50 - Loss: 11757.208180734724\n",
      "Epoch 32/50 - Loss: 11709.74370136774\n",
      "Epoch 33/50 - Loss: 11662.933947869376\n",
      "Epoch 34/50 - Loss: 11616.738642064116\n",
      "Epoch 35/50 - Loss: 11571.120448576752\n",
      "Epoch 36/50 - Loss: 11526.044675342177\n",
      "Epoch 37/50 - Loss: 11481.479009989665\n",
      "Epoch 38/50 - Loss: 11437.393287296061\n",
      "Epoch 39/50 - Loss: 11393.759283623618\n",
      "Epoch 40/50 - Loss: 11350.550534864971\n",
      "Epoch 41/50 - Loss: 11307.74217491987\n",
      "Epoch 42/50 - Loss: 11265.310792153416\n",
      "Epoch 43/50 - Loss: 11223.234301646378\n",
      "Epoch 44/50 - Loss: 11181.49183134395\n",
      "Epoch 45/50 - Loss: 11140.06362047966\n",
      "Epoch 46/50 - Loss: 11098.930928857942\n",
      "Epoch 47/50 - Loss: 11058.075955776914\n",
      "Epoch 48/50 - Loss: 11017.48176752695\n",
      "Epoch 49/50 - Loss: 10977.132232545004\n",
      "Epoch 50/50 - Loss: 10937.011963416528\n",
      "RMSE with bias=True: 0.9356067898824202\n",
      "Epoch 1/100 - Loss: 14314.978901477407\n",
      "Epoch 2/100 - Loss: 14032.956979425202\n",
      "Epoch 3/100 - Loss: 13838.92690441711\n",
      "Epoch 4/100 - Loss: 13685.28377115992\n",
      "Epoch 5/100 - Loss: 13554.017420300053\n",
      "Epoch 6/100 - Loss: 13436.935655017855\n",
      "Epoch 7/100 - Loss: 13329.865319923187\n",
      "Epoch 8/100 - Loss: 13230.455097892518\n",
      "Epoch 9/100 - Loss: 13137.240605773042\n",
      "Epoch 10/100 - Loss: 13049.222639442462\n",
      "Epoch 11/100 - Loss: 12965.667284256988\n",
      "Epoch 12/100 - Loss: 12886.00554983023\n",
      "Epoch 13/100 - Loss: 12809.779357234052\n",
      "Epoch 14/100 - Loss: 12736.610158551206\n",
      "Epoch 15/100 - Loss: 12666.17927619714\n",
      "Epoch 16/100 - Loss: 12598.21473415751\n",
      "Epoch 17/100 - Loss: 12532.481944584299\n",
      "Epoch 18/100 - Loss: 12468.776837534218\n",
      "Epoch 19/100 - Loss: 12406.920627423166\n",
      "Epoch 20/100 - Loss: 12346.755726412304\n",
      "Epoch 21/100 - Loss: 12288.142490593576\n",
      "Epoch 22/100 - Loss: 12230.956588165138\n",
      "Epoch 23/100 - Loss: 12175.086842864706\n",
      "Epoch 24/100 - Loss: 12120.43344747796\n",
      "Epoch 25/100 - Loss: 12066.90647017896\n",
      "Epoch 26/100 - Loss: 12014.424595801576\n",
      "Epoch 27/100 - Loss: 11962.914057860457\n",
      "Epoch 28/100 - Loss: 11912.307727072404\n",
      "Epoch 29/100 - Loss: 11862.544329449074\n",
      "Epoch 30/100 - Loss: 11813.567772518354\n",
      "Epoch 31/100 - Loss: 11765.326562408443\n",
      "Epoch 32/100 - Loss: 11717.77329774666\n",
      "Epoch 33/100 - Loss: 11670.864228846593\n",
      "Epoch 34/100 - Loss: 11624.558872648526\n",
      "Epoch 35/100 - Loss: 11578.819675474388\n",
      "Epoch 36/100 - Loss: 11533.611716943704\n",
      "Epoch 37/100 - Loss: 11488.902449452024\n",
      "Epoch 38/100 - Loss: 11444.661468469792\n",
      "Epoch 39/100 - Loss: 11400.860309640662\n",
      "Epoch 40/100 - Loss: 11357.472269245092\n",
      "Epoch 41/100 - Loss: 11314.472245098461\n",
      "Epoch 42/100 - Loss: 11271.836595366542\n",
      "Epoch 43/100 - Loss: 11229.543013134784\n",
      "Epoch 44/100 - Loss: 11187.570414869786\n",
      "Epoch 45/100 - Loss: 11145.898841160237\n",
      "Epoch 46/100 - Loss: 11104.509368344567\n",
      "Epoch 47/100 - Loss: 11063.384029815585\n",
      "Epoch 48/100 - Loss: 11022.505745952569\n",
      "Epoch 49/100 - Loss: 10981.858261763113\n",
      "Epoch 50/100 - Loss: 10941.426091436922\n",
      "Epoch 51/100 - Loss: 10901.194469111033\n",
      "Epoch 52/100 - Loss: 10861.149305234429\n",
      "Epoch 53/100 - Loss: 10821.277147989806\n",
      "Epoch 54/100 - Loss: 10781.565149297952\n",
      "Epoch 55/100 - Loss: 10742.00103498201\n",
      "Epoch 56/100 - Loss: 10702.57307871445\n",
      "Epoch 57/100 - Loss: 10663.270079414464\n",
      "Epoch 58/100 - Loss: 10624.081341789059\n",
      "Epoch 59/100 - Loss: 10584.996659749837\n",
      "Epoch 60/100 - Loss: 10546.00630245221\n",
      "Epoch 61/100 - Loss: 10507.101002731173\n",
      "Epoch 62/100 - Loss: 10468.271947720363\n",
      "Epoch 63/100 - Loss: 10429.510771456908\n",
      "Epoch 64/100 - Loss: 10390.809549283747\n",
      "Epoch 65/100 - Loss: 10352.160793873585\n",
      "Epoch 66/100 - Loss: 10313.557452698748\n",
      "Epoch 67/100 - Loss: 10274.992906783824\n",
      "Epoch 68/100 - Loss: 10236.46097057444\n",
      "Epoch 69/100 - Loss: 10197.955892762486\n",
      "Epoch 70/100 - Loss: 10159.472357906221\n",
      "Epoch 71/100 - Loss: 10121.005488686229\n",
      "Epoch 72/100 - Loss: 10082.550848633946\n",
      "Epoch 73/100 - Loss: 10044.104445175666\n",
      "Epoch 74/100 - Loss: 10005.662732825442\n",
      "Epoch 75/100 - Loss: 9967.222616367491\n",
      "Epoch 76/100 - Loss: 9928.781453862486\n",
      "Epoch 77/100 - Loss: 9890.33705931538\n",
      "Epoch 78/100 - Loss: 9851.887704842238\n",
      "Epoch 79/100 - Loss: 9813.43212217374\n",
      "Epoch 80/100 - Loss: 9774.9695033389\n",
      "Epoch 81/100 - Loss: 9736.49950037211\n",
      "Epoch 82/100 - Loss: 9698.0222238969\n",
      "Epoch 83/100 - Loss: 9659.53824044182\n",
      "Epoch 84/100 - Loss: 9621.048568356182\n",
      "Epoch 85/100 - Loss: 9582.55467220218\n",
      "Epoch 86/100 - Loss: 9544.05845551133\n",
      "Epoch 87/100 - Loss: 9505.56225180898\n",
      "Epoch 88/100 - Loss: 9467.068813825033\n",
      "Epoch 89/100 - Loss: 9428.581300826836\n",
      "Epoch 90/100 - Loss: 9390.10326403081\n",
      "Epoch 91/100 - Loss: 9351.638630066911\n",
      "Epoch 92/100 - Loss: 9313.191682496541\n",
      "Epoch 93/100 - Loss: 9274.76704140379\n",
      "Epoch 94/100 - Loss: 9236.369641105526\n",
      "Epoch 95/100 - Loss: 9198.004706050466\n",
      "Epoch 96/100 - Loss: 9159.677725001502\n",
      "Epoch 97/100 - Loss: 9121.394423618998\n",
      "Epoch 98/100 - Loss: 9083.160735588415\n",
      "Epoch 99/100 - Loss: 9044.982772455001\n",
      "Epoch 100/100 - Loss: 9006.866792352903\n",
      "RMSE with bias=True: 0.8487837100210126\n",
      "Epoch 1/50 - Loss: 14298.326797340695\n",
      "Epoch 2/50 - Loss: 14018.416394774778\n",
      "Epoch 3/50 - Loss: 13826.060089627077\n",
      "Epoch 4/50 - Loss: 13673.64916982326\n",
      "Epoch 5/50 - Loss: 13543.455495905453\n",
      "Epoch 6/50 - Loss: 13427.4531919324\n",
      "Epoch 7/50 - Loss: 13321.53863893835\n",
      "Epoch 8/50 - Loss: 13223.374698845862\n",
      "Epoch 9/50 - Loss: 13131.48703723433\n",
      "Epoch 10/50 - Loss: 13044.859913859425\n",
      "Epoch 11/50 - Loss: 12962.744113071221\n",
      "Epoch 12/50 - Loss: 12884.559098791786\n",
      "Epoch 13/50 - Loss: 12809.83914742323\n",
      "Epoch 14/50 - Loss: 12738.20128141165\n",
      "Epoch 15/50 - Loss: 12669.324781004649\n",
      "Epoch 16/50 - Loss: 12602.937299726918\n",
      "Epoch 17/50 - Loss: 12538.805005801098\n",
      "Epoch 18/50 - Loss: 12476.725322556596\n",
      "Epoch 19/50 - Loss: 12416.521426811843\n",
      "Epoch 20/50 - Loss: 12358.037981703239\n",
      "Epoch 21/50 - Loss: 12301.137763024044\n",
      "Epoch 22/50 - Loss: 12245.698948808722\n",
      "Epoch 23/50 - Loss: 12191.612911947257\n",
      "Epoch 24/50 - Loss: 12138.782401518889\n",
      "Epoch 25/50 - Loss: 12087.120029489244\n",
      "Epoch 26/50 - Loss: 12036.547000773015\n",
      "Epoch 27/50 - Loss: 11986.992039722756\n",
      "Epoch 28/50 - Loss: 11938.390476912862\n",
      "Epoch 29/50 - Loss: 11890.683467995743\n",
      "Epoch 30/50 - Loss: 11843.817322276254\n",
      "Epoch 31/50 - Loss: 11797.742923097354\n",
      "Epoch 32/50 - Loss: 11752.415225527431\n",
      "Epoch 33/50 - Loss: 11707.792819489394\n",
      "Epoch 34/50 - Loss: 11663.837548558005\n",
      "Epoch 35/50 - Loss: 11620.51417630912\n",
      "Epoch 36/50 - Loss: 11577.790093447444\n",
      "Epoch 37/50 - Loss: 11535.635060020102\n",
      "Epoch 38/50 - Loss: 11494.02097791737\n",
      "Epoch 39/50 - Loss: 11452.92168959401\n",
      "Epoch 40/50 - Loss: 11412.312799551446\n",
      "Epoch 41/50 - Loss: 11372.17151563378\n",
      "Epoch 42/50 - Loss: 11332.476507608415\n",
      "Epoch 43/50 - Loss: 11293.20778086932\n",
      "Epoch 44/50 - Loss: 11254.346563394556\n",
      "Epoch 45/50 - Loss: 11215.875204351965\n",
      "Epoch 46/50 - Loss: 11177.777082962137\n",
      "Epoch 47/50 - Loss: 11140.036526413185\n",
      "Epoch 48/50 - Loss: 11102.638735781828\n",
      "Epoch 49/50 - Loss: 11065.569719049297\n",
      "Epoch 50/50 - Loss: 11028.816230419508\n",
      "RMSE with bias=True: 0.9396930554422883\n",
      "Epoch 1/100 - Loss: 14296.232818588149\n",
      "Epoch 2/100 - Loss: 14017.82090993088\n",
      "Epoch 3/100 - Loss: 13825.548242533678\n",
      "Epoch 4/100 - Loss: 13672.802492669913\n",
      "Epoch 5/100 - Loss: 13542.163607648223\n",
      "Epoch 6/100 - Loss: 13425.71411079423\n",
      "Epoch 7/100 - Loss: 13319.38754762184\n",
      "Epoch 8/100 - Loss: 13220.856705680604\n",
      "Epoch 9/100 - Loss: 13128.646767665727\n",
      "Epoch 10/100 - Loss: 13041.73778071841\n",
      "Epoch 11/100 - Loss: 12959.375256060177\n",
      "Epoch 12/100 - Loss: 12880.973374731557\n",
      "Epoch 13/100 - Loss: 12806.061511019041\n",
      "Epoch 14/100 - Loss: 12734.252286153633\n",
      "Epoch 15/100 - Loss: 12665.221090384835\n",
      "Epoch 16/100 - Loss: 12598.692165871404\n",
      "Epoch 17/100 - Loss: 12534.428700816106\n",
      "Epoch 18/100 - Loss: 12472.225519813088\n",
      "Epoch 19/100 - Loss: 12411.9035343708\n",
      "Epoch 20/100 - Loss: 12353.305432005678\n",
      "Epoch 21/100 - Loss: 12296.292263547835\n",
      "Epoch 22/100 - Loss: 12240.74069835521\n",
      "Epoch 23/100 - Loss: 12186.54078691427\n",
      "Epoch 24/100 - Loss: 12133.594116112177\n",
      "Epoch 25/100 - Loss: 12081.812273384792\n",
      "Epoch 26/100 - Loss: 12031.115557320625\n",
      "Epoch 27/100 - Loss: 11981.431887387707\n",
      "Epoch 28/100 - Loss: 11932.695876297179\n",
      "Epoch 29/100 - Loss: 11884.84803646312\n",
      "Epoch 30/100 - Loss: 11837.834097928047\n",
      "Epoch 31/100 - Loss: 11791.604419605103\n",
      "Epoch 32/100 - Loss: 11746.113479115607\n",
      "Epoch 33/100 - Loss: 11701.319429184025\n",
      "Epoch 34/100 - Loss: 11657.183710657398\n",
      "Epoch 35/100 - Loss: 11613.670713903319\n",
      "Epoch 36/100 - Loss: 11570.747481694125\n",
      "Epoch 37/100 - Loss: 11528.383447789582\n",
      "Epoch 38/100 - Loss: 11486.550206334085\n",
      "Epoch 39/100 - Loss: 11445.22130792967\n",
      "Epoch 40/100 - Loss: 11404.37207886445\n",
      "Epoch 41/100 - Loss: 11363.979460495846\n",
      "Epoch 42/100 - Loss: 11324.021866216384\n",
      "Epoch 43/100 - Loss: 11284.47905379856\n",
      "Epoch 44/100 - Loss: 11245.332011219998\n",
      "Epoch 45/100 - Loss: 11206.562854334694\n",
      "Epoch 46/100 - Loss: 11168.15473497242\n",
      "Epoch 47/100 - Loss: 11130.091758244567\n",
      "Epoch 48/100 - Loss: 11092.358907989072\n",
      "Epoch 49/100 - Loss: 11054.941979431103\n",
      "Epoch 50/100 - Loss: 11017.827518251082\n",
      "Epoch 51/100 - Loss: 10981.002765356381\n",
      "Epoch 52/100 - Loss: 10944.455606739184\n",
      "Epoch 53/100 - Loss: 10908.174527879413\n",
      "Epoch 54/100 - Loss: 10872.148572219028\n",
      "Epoch 55/100 - Loss: 10836.36730328754\n",
      "Epoch 56/100 - Loss: 10800.8207701126\n",
      "Epoch 57/100 - Loss: 10765.499475587541\n",
      "Epoch 58/100 - Loss: 10730.394347510019\n",
      "Epoch 59/100 - Loss: 10695.496712034654\n",
      "Epoch 60/100 - Loss: 10660.798269313646\n",
      "Epoch 61/100 - Loss: 10626.291071124137\n",
      "Epoch 62/100 - Loss: 10591.967500300698\n",
      "Epoch 63/100 - Loss: 10557.820251814497\n",
      "Epoch 64/100 - Loss: 10523.842315354193\n",
      "Epoch 65/100 - Loss: 10490.02695928023\n",
      "Epoch 66/100 - Loss: 10456.367715836968\n",
      "Epoch 67/100 - Loss: 10422.858367519231\n",
      "Epoch 68/100 - Loss: 10389.492934498965\n",
      "Epoch 69/100 - Loss: 10356.265663027907\n",
      "Epoch 70/100 - Loss: 10323.171014739735\n",
      "Epoch 71/100 - Loss: 10290.203656783015\n",
      "Epoch 72/100 - Loss: 10257.358452720546\n",
      "Epoch 73/100 - Loss: 10224.630454140075\n",
      "Epoch 74/100 - Loss: 10192.014892921788\n",
      "Epoch 75/100 - Loss: 10159.507174116887\n",
      "Epoch 76/100 - Loss: 10127.102869392327\n",
      "Epoch 77/100 - Loss: 10094.797711001434\n",
      "Epoch 78/100 - Loss: 10062.587586244368\n",
      "Epoch 79/100 - Loss: 10030.468532383176\n",
      "Epoch 80/100 - Loss: 9998.436731980384\n",
      "Epoch 81/100 - Loss: 9966.488508630917\n",
      "Epoch 82/100 - Loss: 9934.620323060997\n",
      "Epoch 83/100 - Loss: 9902.828769567339\n",
      "Epoch 84/100 - Loss: 9871.110572772672\n",
      "Epoch 85/100 - Loss: 9839.462584675388\n",
      "Epoch 86/100 - Loss: 9807.881781970927\n",
      "Epoch 87/100 - Loss: 9776.365263625383\n",
      "Epoch 88/100 - Loss: 9744.910248681494\n",
      "Epoch 89/100 - Loss: 9713.514074278517\n",
      "Epoch 90/100 - Loss: 9682.174193867397\n",
      "Epoch 91/100 - Loss: 9650.88817560616\n",
      "Epoch 92/100 - Loss: 9619.653700916551\n",
      "Epoch 93/100 - Loss: 9588.468563187847\n",
      "Epoch 94/100 - Loss: 9557.33066661114\n",
      "Epoch 95/100 - Loss: 9526.23802512937\n",
      "Epoch 96/100 - Loss: 9495.188761488867\n",
      "Epoch 97/100 - Loss: 9464.181106377246\n",
      "Epoch 98/100 - Loss: 9433.21339763438\n",
      "Epoch 99/100 - Loss: 9402.284079522027\n",
      "Epoch 100/100 - Loss: 9371.391702039356\n",
      "RMSE with bias=True: 0.8661756226968911\n",
      "Epoch 1/50 - Loss: 13969.033584705636\n",
      "Epoch 2/50 - Loss: 13319.418218252262\n",
      "Epoch 3/50 - Loss: 12884.942460267988\n",
      "Epoch 4/50 - Loss: 12533.172880415303\n",
      "Epoch 5/50 - Loss: 12229.080814791378\n",
      "Epoch 6/50 - Loss: 11955.495122334534\n",
      "Epoch 7/50 - Loss: 11702.329334230884\n",
      "Epoch 8/50 - Loss: 11462.994419627454\n",
      "Epoch 9/50 - Loss: 11232.792555084829\n",
      "Epoch 10/50 - Loss: 11008.100334222092\n",
      "Epoch 11/50 - Loss: 10785.933159008975\n",
      "Epoch 12/50 - Loss: 10563.722907453974\n",
      "Epoch 13/50 - Loss: 10339.236993363958\n",
      "Epoch 14/50 - Loss: 10110.608861157669\n",
      "Epoch 15/50 - Loss: 9876.46317348786\n",
      "Epoch 16/50 - Loss: 9636.110146224708\n",
      "Epoch 17/50 - Loss: 9389.755828631993\n",
      "Epoch 18/50 - Loss: 9138.639015839013\n",
      "Epoch 19/50 - Loss: 8884.98609263144\n",
      "Epoch 20/50 - Loss: 8631.707009747028\n",
      "Epoch 21/50 - Loss: 8381.855263006857\n",
      "Epoch 22/50 - Loss: 8138.00527880002\n",
      "Epoch 23/50 - Loss: 7901.774226945529\n",
      "Epoch 24/50 - Loss: 7673.661619073372\n",
      "Epoch 25/50 - Loss: 7453.22408274406\n",
      "Epoch 26/50 - Loss: 7239.453778053251\n",
      "Epoch 27/50 - Loss: 7031.179885082423\n",
      "Epoch 28/50 - Loss: 6827.364705582464\n",
      "Epoch 29/50 - Loss: 6627.25407944559\n",
      "Epoch 30/50 - Loss: 6430.406477120204\n",
      "Epoch 31/50 - Loss: 6236.648721327666\n",
      "Epoch 32/50 - Loss: 6046.001497399187\n",
      "Epoch 33/50 - Loss: 5858.602931652589\n",
      "Epoch 34/50 - Loss: 5674.644670710042\n",
      "Epoch 35/50 - Loss: 5494.325541513012\n",
      "Epoch 36/50 - Loss: 5317.822578263471\n",
      "Epoch 37/50 - Loss: 5145.2766012226575\n",
      "Epoch 38/50 - Loss: 4976.788532745567\n",
      "Epoch 39/50 - Loss: 4812.422584303124\n",
      "Epoch 40/50 - Loss: 4652.212958656143\n",
      "Epoch 41/50 - Loss: 4496.171514056121\n",
      "Epoch 42/50 - Loss: 4344.29471860046\n",
      "Epoch 43/50 - Loss: 4196.569022684361\n",
      "Epoch 44/50 - Loss: 4052.9744000469377\n",
      "Epoch 45/50 - Loss: 3913.486220593156\n",
      "Epoch 46/50 - Loss: 3778.075836766386\n",
      "Epoch 47/50 - Loss: 3646.710332841393\n",
      "Epoch 48/50 - Loss: 3519.3518543149835\n",
      "Epoch 49/50 - Loss: 3395.9568489641306\n",
      "Epoch 50/50 - Loss: 3276.4754474356914\n",
      "RMSE with bias=True: 0.5039772742260107\n",
      "Epoch 1/100 - Loss: 13993.55529100621\n",
      "Epoch 2/100 - Loss: 13346.5720292983\n",
      "Epoch 3/100 - Loss: 12914.030060430177\n",
      "Epoch 4/100 - Loss: 12564.349461394515\n",
      "Epoch 5/100 - Loss: 12262.62470119557\n",
      "Epoch 6/100 - Loss: 11991.786904648283\n",
      "Epoch 7/100 - Loss: 11741.846031863524\n",
      "Epoch 8/100 - Loss: 11506.312114793278\n",
      "Epoch 9/100 - Loss: 11280.594010268072\n",
      "Epoch 10/100 - Loss: 11061.182845783927\n",
      "Epoch 11/100 - Loss: 10845.210791304173\n",
      "Epoch 12/100 - Loss: 10630.215320806232\n",
      "Epoch 13/100 - Loss: 10414.034806290412\n",
      "Epoch 14/100 - Loss: 10194.804372730843\n",
      "Epoch 15/100 - Loss: 9971.038026098302\n",
      "Epoch 16/100 - Loss: 9741.781690854972\n",
      "Epoch 17/100 - Loss: 9506.803849097838\n",
      "Epoch 18/100 - Loss: 9266.760613426732\n",
      "Epoch 19/100 - Loss: 9023.245190188192\n",
      "Epoch 20/100 - Loss: 8778.63448730448\n",
      "Epoch 21/100 - Loss: 8535.702856898926\n",
      "Epoch 22/100 - Loss: 8297.078656768232\n",
      "Epoch 23/100 - Loss: 8064.718326568638\n",
      "Epoch 24/100 - Loss: 7839.589360464219\n",
      "Epoch 25/100 - Loss: 7621.660727365017\n",
      "Epoch 26/100 - Loss: 7410.155743087311\n",
      "Epoch 27/100 - Loss: 7203.924381051098\n",
      "Epoch 28/100 - Loss: 7001.787906550737\n",
      "Epoch 29/100 - Loss: 6802.771340208169\n",
      "Epoch 30/100 - Loss: 6606.210411413469\n",
      "Epoch 31/100 - Loss: 6411.7622513164615\n",
      "Epoch 32/100 - Loss: 6219.359770276699\n",
      "Epoch 33/100 - Loss: 6029.14231320799\n",
      "Epoch 34/100 - Loss: 5841.3832856524305\n",
      "Epoch 35/100 - Loss: 5656.425740025128\n",
      "Epoch 36/100 - Loss: 5474.630766852486\n",
      "Epoch 37/100 - Loss: 5296.340041722759\n",
      "Epoch 38/100 - Loss: 5121.851877906583\n",
      "Epoch 39/100 - Loss: 4951.408922508052\n",
      "Epoch 40/100 - Loss: 4785.194939388859\n",
      "Epoch 41/100 - Loss: 4623.337879531907\n",
      "Epoch 42/100 - Loss: 4465.916603827535\n",
      "Epoch 43/100 - Loss: 4312.96909305331\n",
      "Epoch 44/100 - Loss: 4164.500606532511\n",
      "Epoch 45/100 - Loss: 4020.4908842804107\n",
      "Epoch 46/100 - Loss: 3880.9000162023185\n",
      "Epoch 47/100 - Loss: 3745.6729717139874\n",
      "Epoch 48/100 - Loss: 3614.74299113971\n",
      "Epoch 49/100 - Loss: 3488.034116977703\n",
      "Epoch 50/100 - Loss: 3365.463132553448\n",
      "Epoch 51/100 - Loss: 3246.941119856664\n",
      "Epoch 52/100 - Loss: 3132.3747796032076\n",
      "Epoch 53/100 - Loss: 3021.667594689508\n",
      "Epoch 54/100 - Loss: 2914.72087243883\n",
      "Epoch 55/100 - Loss: 2811.4346730386073\n",
      "Epoch 56/100 - Loss: 2711.7086186782317\n",
      "Epoch 57/100 - Loss: 2615.4425757008526\n",
      "Epoch 58/100 - Loss: 2522.5372061012245\n",
      "Epoch 59/100 - Loss: 2432.8943912749155\n",
      "Epoch 60/100 - Loss: 2346.4175375260775\n",
      "Epoch 61/100 - Loss: 2263.0117780203764\n",
      "Epoch 62/100 - Loss: 2182.584089034514\n",
      "Epoch 63/100 - Loss: 2105.04333949047\n",
      "Epoch 64/100 - Loss: 2030.3002921960356\n",
      "Epoch 65/100 - Loss: 1958.267573411789\n",
      "Epoch 66/100 - Loss: 1888.859624809409\n",
      "Epoch 67/100 - Loss: 1821.9926490014163\n",
      "Epoch 68/100 - Loss: 1757.5845569337878\n",
      "Epoch 69/100 - Loss: 1695.5549227699623\n",
      "Epoch 70/100 - Loss: 1635.8249495925656\n",
      "Epoch 71/100 - Loss: 1578.3174473710183\n",
      "Epoch 72/100 - Loss: 1522.956823198879\n",
      "Epoch 73/100 - Loss: 1469.6690827646823\n",
      "Epoch 74/100 - Loss: 1418.3818413367767\n",
      "Epoch 75/100 - Loss: 1369.0243421562932\n",
      "Epoch 76/100 - Loss: 1321.5274799813635\n",
      "Epoch 77/100 - Loss: 1275.8238275531953\n",
      "Epoch 78/100 - Loss: 1231.847662908387\n",
      "Epoch 79/100 - Loss: 1189.5349956984771\n",
      "Epoch 80/100 - Loss: 1148.8235909619652\n",
      "Epoch 81/100 - Loss: 1109.6529890980275\n",
      "Epoch 82/100 - Loss: 1071.964521093732\n",
      "Epoch 83/100 - Loss: 1035.701318343249\n",
      "Epoch 84/100 - Loss: 1000.8083166587236\n",
      "Epoch 85/100 - Loss: 967.2322543012248\n",
      "Epoch 86/100 - Loss: 934.9216640547568\n",
      "Epoch 87/100 - Loss: 903.8268595255516\n",
      "Epoch 88/100 - Loss: 873.8999159745176\n",
      "Epoch 89/100 - Loss: 845.0946460845084\n",
      "Epoch 90/100 - Loss: 817.3665711301492\n",
      "Epoch 91/100 - Loss: 790.6728880587034\n",
      "Epoch 92/100 - Loss: 764.9724330109818\n",
      "Epoch 93/100 - Loss: 740.2256418136323\n",
      "Epoch 94/100 - Loss: 716.3945079636619\n",
      "Epoch 95/100 - Loss: 693.4425386037734\n",
      "Epoch 96/100 - Loss: 671.3347089581229\n",
      "Epoch 97/100 - Loss: 650.0374156629427\n",
      "Epoch 98/100 - Loss: 629.5184293883812\n",
      "Epoch 99/100 - Loss: 609.746847108376\n",
      "Epoch 100/100 - Loss: 590.6930443352805\n",
      "RMSE with bias=True: 0.21412660744410042\n",
      "Epoch 1/50 - Loss: 13986.142764324051\n",
      "Epoch 2/50 - Loss: 13336.692955239621\n",
      "Epoch 3/50 - Loss: 12905.723947784458\n",
      "Epoch 4/50 - Loss: 12559.778179353385\n",
      "Epoch 5/50 - Loss: 12263.360939438839\n",
      "Epoch 6/50 - Loss: 11999.304344155307\n",
      "Epoch 7/50 - Loss: 11757.754281588808\n",
      "Epoch 8/50 - Loss: 11532.511342671785\n",
      "Epoch 9/50 - Loss: 11319.398772453229\n",
      "Epoch 10/50 - Loss: 11115.433079173466\n",
      "Epoch 11/50 - Loss: 10918.370558336122\n",
      "Epoch 12/50 - Loss: 10726.446273101858\n",
      "Epoch 13/50 - Loss: 10538.218326266393\n",
      "Epoch 14/50 - Loss: 10352.473753369752\n",
      "Epoch 15/50 - Loss: 10168.173424282051\n",
      "Epoch 16/50 - Loss: 9984.423925058549\n",
      "Epoch 17/50 - Loss: 9800.469678074041\n",
      "Epoch 18/50 - Loss: 9615.700862581207\n",
      "Epoch 19/50 - Loss: 9429.673082559237\n",
      "Epoch 20/50 - Loss: 9242.133775443795\n",
      "Epoch 21/50 - Loss: 9053.048610492116\n",
      "Epoch 22/50 - Loss: 8862.619372306852\n",
      "Epoch 23/50 - Loss: 8671.28415493076\n",
      "Epoch 24/50 - Loss: 8479.692275470285\n",
      "Epoch 25/50 - Loss: 8288.650840769129\n",
      "Epoch 26/50 - Loss: 8099.04688180803\n",
      "Epoch 27/50 - Loss: 7911.756427619034\n",
      "Epoch 28/50 - Loss: 7727.556895295719\n",
      "Epoch 29/50 - Loss: 7547.059279428845\n",
      "Epoch 30/50 - Loss: 7370.671394053189\n",
      "Epoch 31/50 - Loss: 7198.594898450927\n",
      "Epoch 32/50 - Loss: 7030.850487715849\n",
      "Epoch 33/50 - Loss: 6867.320426292885\n",
      "Epoch 34/50 - Loss: 6707.796641354462\n",
      "Epoch 35/50 - Loss: 6552.025007054721\n",
      "Epoch 36/50 - Loss: 6399.740384910586\n",
      "Epoch 37/50 - Loss: 6250.690726722356\n",
      "Epoch 38/50 - Loss: 6104.651146156429\n",
      "Epoch 39/50 - Loss: 5961.430153965154\n",
      "Epoch 40/50 - Loss: 5820.870526130907\n",
      "Epoch 41/50 - Loss: 5682.846962723714\n",
      "Epoch 42/50 - Loss: 5547.262156871421\n",
      "Epoch 43/50 - Loss: 5414.042351595106\n",
      "Epoch 44/50 - Loss: 5283.133021013716\n",
      "Epoch 45/50 - Loss: 5154.494997321214\n",
      "Epoch 46/50 - Loss: 5028.101162509165\n",
      "Epoch 47/50 - Loss: 4903.933706954584\n",
      "Epoch 48/50 - Loss: 4781.981898439149\n",
      "Epoch 49/50 - Loss: 4662.240282849623\n",
      "Epoch 50/50 - Loss: 4544.707235924939\n",
      "RMSE with bias=True: 0.596686173751581\n",
      "Epoch 1/100 - Loss: 13970.904472115415\n",
      "Epoch 2/100 - Loss: 13329.589091563566\n",
      "Epoch 3/100 - Loss: 12902.486173890296\n",
      "Epoch 4/100 - Loss: 12558.493735645812\n",
      "Epoch 5/100 - Loss: 12263.027007579933\n",
      "Epoch 6/100 - Loss: 11999.37421360752\n",
      "Epoch 7/100 - Loss: 11757.916814084232\n",
      "Epoch 8/100 - Loss: 11532.574940543202\n",
      "Epoch 9/100 - Loss: 11319.228111531436\n",
      "Epoch 10/100 - Loss: 11114.913753075685\n",
      "Epoch 11/100 - Loss: 10917.38928122917\n",
      "Epoch 12/100 - Loss: 10724.8805817027\n",
      "Epoch 13/100 - Loss: 10535.933041670845\n",
      "Epoch 14/100 - Loss: 10349.32327733001\n",
      "Epoch 15/100 - Loss: 10164.009911325425\n",
      "Epoch 16/100 - Loss: 9979.11174094485\n",
      "Epoch 17/100 - Loss: 9793.90635988978\n",
      "Epoch 18/100 - Loss: 9607.843974696987\n",
      "Epoch 19/100 - Loss: 9420.570877843855\n",
      "Epoch 20/100 - Loss: 9231.955552055719\n",
      "Epoch 21/100 - Loss: 9042.108545244042\n",
      "Epoch 22/100 - Loss: 8851.386235630793\n",
      "Epoch 23/100 - Loss: 8660.36972342679\n",
      "Epoch 24/100 - Loss: 8469.814284668553\n",
      "Epoch 25/100 - Loss: 8280.571911794448\n",
      "Epoch 26/100 - Loss: 8093.497615746017\n",
      "Epoch 27/100 - Loss: 7909.35629097484\n",
      "Epoch 28/100 - Loss: 7728.74813548669\n",
      "Epoch 29/100 - Loss: 7552.065899534365\n",
      "Epoch 30/100 - Loss: 7379.488396574486\n",
      "Epoch 31/100 - Loss: 7211.005404885265\n",
      "Epoch 32/100 - Loss: 7046.462794412167\n",
      "Epoch 33/100 - Loss: 6885.614998790601\n",
      "Epoch 34/100 - Loss: 6728.174149809467\n",
      "Epoch 35/100 - Loss: 6573.84935166979\n",
      "Epoch 36/100 - Loss: 6422.373748220384\n",
      "Epoch 37/100 - Loss: 6273.520068054588\n",
      "Epoch 38/100 - Loss: 6127.106937854207\n",
      "Epoch 39/100 - Loss: 5982.99870821148\n",
      "Epoch 40/100 - Loss: 5841.101293657621\n",
      "Epoch 41/100 - Loss: 5701.355986711219\n",
      "Epoch 42/100 - Loss: 5563.732619524822\n",
      "Epoch 43/100 - Loss: 5428.222941179832\n",
      "Epoch 44/100 - Loss: 5294.834693386208\n",
      "Epoch 45/100 - Loss: 5163.586597991777\n",
      "Epoch 46/100 - Loss: 5034.504295377042\n",
      "Epoch 47/100 - Loss: 4907.617169882997\n",
      "Epoch 48/100 - Loss: 4782.955946072447\n",
      "Epoch 49/100 - Loss: 4660.550921172625\n",
      "Epoch 50/100 - Loss: 4540.43070174482\n",
      "Epoch 51/100 - Loss: 4422.62132707446\n",
      "Epoch 52/100 - Loss: 4307.145681351811\n",
      "Epoch 53/100 - Loss: 4194.023117067847\n",
      "Epoch 54/100 - Loss: 4083.26923062194\n",
      "Epoch 55/100 - Loss: 3974.895746708188\n",
      "Epoch 56/100 - Loss: 3868.9104803076657\n",
      "Epoch 57/100 - Loss: 3765.317354306913\n",
      "Epoch 58/100 - Loss: 3664.1164574034965\n",
      "Epoch 59/100 - Loss: 3565.3041316222034\n",
      "Epoch 60/100 - Loss: 3468.8730819936623\n",
      "Epoch 61/100 - Loss: 3374.8125031649624\n",
      "Epoch 62/100 - Loss: 3283.1082192448425\n",
      "Epoch 63/100 - Loss: 3193.7428342482353\n",
      "Epoch 64/100 - Loss: 3106.6958912381924\n",
      "Epoch 65/100 - Loss: 3021.944038757061\n",
      "Epoch 66/100 - Loss: 2939.4612034487163\n",
      "Epoch 67/100 - Loss: 2859.2187679419344\n",
      "Epoch 68/100 - Loss: 2781.185753125375\n",
      "Epoch 69/100 - Loss: 2705.329003925033\n",
      "Epoch 70/100 - Loss: 2631.6133776296774\n",
      "Epoch 71/100 - Loss: 2560.0019337174363\n",
      "Epoch 72/100 - Loss: 2490.4561240480552\n",
      "Epoch 73/100 - Loss: 2422.9359822109923\n",
      "Epoch 74/100 - Loss: 2357.4003107772005\n",
      "Epoch 75/100 - Loss: 2293.8068651968456\n",
      "Epoch 76/100 - Loss: 2232.1125331183434\n",
      "Epoch 77/100 - Loss: 2172.2735079750046\n",
      "Epoch 78/100 - Loss: 2114.2454557891933\n",
      "Epoch 79/100 - Loss: 2057.983674272959\n",
      "Epoch 80/100 - Loss: 2003.4432434509085\n",
      "Epoch 81/100 - Loss: 1950.5791671885759\n",
      "Epoch 82/100 - Loss: 1899.3465051700382\n",
      "Epoch 83/100 - Loss: 1849.7004950250703\n",
      "Epoch 84/100 - Loss: 1801.5966644548657\n",
      "Epoch 85/100 - Loss: 1754.9909333421629\n",
      "Epoch 86/100 - Loss: 1709.8397059526205\n",
      "Epoch 87/100 - Loss: 1666.0999534401312\n",
      "Epoch 88/100 - Loss: 1623.7292869578516\n",
      "Epoch 89/100 - Loss: 1582.6860217478113\n",
      "Epoch 90/100 - Loss: 1542.9292326399761\n",
      "Epoch 91/100 - Loss: 1504.4188014323363\n",
      "Epoch 92/100 - Loss: 1467.115456653234\n",
      "Epoch 93/100 - Loss: 1430.9808062243521\n",
      "Epoch 94/100 - Loss: 1395.9773635503627\n",
      "Epoch 95/100 - Loss: 1362.068567559892\n",
      "Epoch 96/100 - Loss: 1329.2187972152365\n",
      "Epoch 97/100 - Loss: 1297.3933809943526\n",
      "Epoch 98/100 - Loss: 1266.5586018308743\n",
      "Epoch 99/100 - Loss: 1236.6816979768328\n",
      "Epoch 100/100 - Loss: 1207.7308602288313\n",
      "RMSE with bias=True: 0.30816644857373404\n",
      "Epoch 1/50 - Loss: 13971.185268839745\n",
      "Epoch 2/50 - Loss: 13334.455264771845\n",
      "Epoch 3/50 - Loss: 12912.932451950413\n",
      "Epoch 4/50 - Loss: 12575.517031770132\n",
      "Epoch 5/50 - Loss: 12287.400692697976\n",
      "Epoch 6/50 - Loss: 12031.928957207403\n",
      "Epoch 7/50 - Loss: 11799.619900323138\n",
      "Epoch 8/50 - Loss: 11584.562197656562\n",
      "Epoch 9/50 - Loss: 11382.825519391648\n",
      "Epoch 10/50 - Loss: 11191.659390468261\n",
      "Epoch 11/50 - Loss: 11009.0567188291\n",
      "Epoch 12/50 - Loss: 10833.50129871693\n",
      "Epoch 13/50 - Loss: 10663.813997781092\n",
      "Epoch 14/50 - Loss: 10499.054742998798\n",
      "Epoch 15/50 - Loss: 10338.457619974733\n",
      "Epoch 16/50 - Loss: 10181.38652246342\n",
      "Epoch 17/50 - Loss: 10027.304094141375\n",
      "Epoch 18/50 - Loss: 9875.749605814994\n",
      "Epoch 19/50 - Loss: 9726.323062948466\n",
      "Epoch 20/50 - Loss: 9578.673813868347\n",
      "Epoch 21/50 - Loss: 9432.492522880606\n",
      "Epoch 22/50 - Loss: 9287.505741242256\n",
      "Epoch 23/50 - Loss: 9143.47253796433\n",
      "Epoch 24/50 - Loss: 9000.182789877686\n",
      "Epoch 25/50 - Loss: 8857.456804307834\n",
      "Epoch 26/50 - Loss: 8715.145975652465\n",
      "Epoch 27/50 - Loss: 8573.134171855194\n",
      "Epoch 28/50 - Loss: 8431.339519682033\n",
      "Epoch 29/50 - Loss: 8289.71622119221\n",
      "Epoch 30/50 - Loss: 8148.256002149333\n",
      "Epoch 31/50 - Loss: 8006.988782214272\n",
      "Epoch 32/50 - Loss: 7865.982182259142\n",
      "Epoch 33/50 - Loss: 7725.339558275373\n",
      "Epoch 34/50 - Loss: 7585.196378914253\n",
      "Epoch 35/50 - Loss: 7445.7149383900305\n",
      "Epoch 36/50 - Loss: 7307.077599158332\n",
      "Epoch 37/50 - Loss: 7169.478959099296\n",
      "Epoch 38/50 - Loss: 7033.11749987634\n",
      "Epoch 39/50 - Loss: 6898.187363660366\n",
      "Epoch 40/50 - Loss: 6764.870903648439\n",
      "Epoch 41/50 - Loss: 6633.332557750774\n",
      "Epoch 42/50 - Loss: 6503.714422736307\n",
      "Epoch 43/50 - Loss: 6376.133691925257\n",
      "Epoch 44/50 - Loss: 6250.681903642509\n",
      "Epoch 45/50 - Loss: 6127.42576665504\n",
      "Epoch 46/50 - Loss: 6006.409207217142\n",
      "Epoch 47/50 - Loss: 5887.656228899268\n",
      "Epoch 48/50 - Loss: 5771.174185266853\n",
      "Epoch 49/50 - Loss: 5656.957120903108\n",
      "Epoch 50/50 - Loss: 5544.988918320309\n",
      "RMSE with bias=True: 0.6612721722289796\n",
      "Epoch 1/100 - Loss: 13970.945076547947\n",
      "Epoch 2/100 - Loss: 13323.514365751966\n",
      "Epoch 3/100 - Loss: 12895.414338488288\n",
      "Epoch 4/100 - Loss: 12553.014199430158\n",
      "Epoch 5/100 - Loss: 12260.549248665988\n",
      "Epoch 6/100 - Loss: 12000.903019073827\n",
      "Epoch 7/100 - Loss: 11764.332592911727\n",
      "Epoch 8/100 - Loss: 11544.760431359426\n",
      "Epoch 9/100 - Loss: 11338.13804612754\n",
      "Epoch 10/100 - Loss: 11141.622427020155\n",
      "Epoch 11/100 - Loss: 10953.128549500787\n",
      "Epoch 12/100 - Loss: 10771.071777420024\n",
      "Epoch 13/100 - Loss: 10594.212315781622\n",
      "Epoch 14/100 - Loss: 10421.557577867907\n",
      "Epoch 15/100 - Loss: 10252.299141037893\n",
      "Epoch 16/100 - Loss: 10085.771368861242\n",
      "Epoch 17/100 - Loss: 9921.42418902343\n",
      "Epoch 18/100 - Loss: 9758.805421374365\n",
      "Epoch 19/100 - Loss: 9597.549640667736\n",
      "Epoch 20/100 - Loss: 9437.371432579857\n",
      "Epoch 21/100 - Loss: 9278.061378668055\n",
      "Epoch 22/100 - Loss: 9119.48337155067\n",
      "Epoch 23/100 - Loss: 8961.57203611194\n",
      "Epoch 24/100 - Loss: 8804.329201114635\n",
      "Epoch 25/100 - Loss: 8647.81858767505\n",
      "Epoch 26/100 - Loss: 8492.158188641173\n",
      "Epoch 27/100 - Loss: 8337.51020505611\n",
      "Epoch 28/100 - Loss: 8184.0688457309825\n",
      "Epoch 29/100 - Loss: 8032.046716162236\n",
      "Epoch 30/100 - Loss: 7881.660841956306\n",
      "Epoch 31/100 - Loss: 7733.11951783487\n",
      "Epoch 32/100 - Loss: 7586.611109004276\n",
      "Epoch 33/100 - Loss: 7442.29566963629\n",
      "Epoch 34/100 - Loss: 7300.299844087264\n",
      "Epoch 35/100 - Loss: 7160.715071025717\n",
      "Epoch 36/100 - Loss: 7023.598712125303\n",
      "Epoch 37/100 - Loss: 6888.977445356252\n",
      "Epoch 38/100 - Loss: 6756.852129868231\n",
      "Epoch 39/100 - Loss: 6627.203357872819\n",
      "Epoch 40/100 - Loss: 6499.997023812287\n",
      "Epoch 41/100 - Loss: 6375.189415431467\n",
      "Epoch 42/100 - Loss: 6252.731520493057\n",
      "Epoch 43/100 - Loss: 6132.572413535468\n",
      "Epoch 44/100 - Loss: 6014.66172041421\n",
      "Epoch 45/100 - Loss: 5898.951248436917\n",
      "Epoch 46/100 - Loss: 5785.395919841452\n",
      "Epoch 47/100 - Loss: 5673.954164242739\n",
      "Epoch 48/100 - Loss: 5564.5879210829125\n",
      "Epoch 49/100 - Loss: 5457.262385002243\n",
      "Epoch 50/100 - Loss: 5351.9456025555355\n",
      "Epoch 51/100 - Loss: 5248.608002918397\n",
      "Epoch 52/100 - Loss: 5147.221921339052\n",
      "Epoch 53/100 - Loss: 5047.761153763479\n",
      "Epoch 54/100 - Loss: 4950.200564895959\n",
      "Epoch 55/100 - Loss: 4854.515759852887\n",
      "Epoch 56/100 - Loss: 4760.682821073922\n",
      "Epoch 57/100 - Loss: 4668.678106618735\n",
      "Epoch 58/100 - Loss: 4578.478102760303\n",
      "Epoch 59/100 - Loss: 4490.059322268149\n",
      "Epoch 60/100 - Loss: 4403.3982394524555\n",
      "Epoch 61/100 - Loss: 4318.471253495344\n",
      "Epoch 62/100 - Loss: 4235.254672512584\n",
      "Epoch 63/100 - Loss: 4153.7247119386175\n",
      "Epoch 64/100 - Loss: 4073.8575020414214\n",
      "Epoch 65/100 - Loss: 3995.629100547506\n",
      "Epoch 66/100 - Loss: 3919.0155074223253\n",
      "Epoch 67/100 - Loss: 3843.9926797709463\n",
      "Epoch 68/100 - Loss: 3770.5365455837614\n",
      "Epoch 69/100 - Loss: 3698.623015656333\n",
      "Epoch 70/100 - Loss: 3628.227993465659\n",
      "Epoch 71/100 - Loss: 3559.327383110123\n",
      "Epoch 72/100 - Loss: 3491.8970956335793\n",
      "Epoch 73/100 - Loss: 3425.9130541741138\n",
      "Epoch 74/100 - Loss: 3361.351198429282\n",
      "Epoch 75/100 - Loss: 3298.187488924155\n",
      "Epoch 76/100 - Loss: 3236.397911528286\n",
      "Epoch 77/100 - Loss: 3175.958482599741\n",
      "Epoch 78/100 - Loss: 3116.845255055169\n",
      "Epoch 79/100 - Loss: 3059.034325579254\n",
      "Epoch 80/100 - Loss: 3002.5018431037224\n",
      "Epoch 81/100 - Loss: 2947.224018607084\n",
      "Epoch 82/100 - Loss: 2893.177136218753\n",
      "Epoch 83/100 - Loss: 2840.337565552365\n",
      "Epoch 84/100 - Loss: 2788.6817751461413\n",
      "Epoch 85/100 - Loss: 2738.186346853783\n",
      "Epoch 86/100 - Loss: 2688.82799100373\n",
      "Epoch 87/100 - Loss: 2640.5835621307638\n",
      "Epoch 88/100 - Loss: 2593.430075077401\n",
      "Epoch 89/100 - Loss: 2547.3447212636634\n",
      "Epoch 90/100 - Loss: 2502.3048849310435\n",
      "Epoch 91/100 - Loss: 2458.288159178282\n",
      "Epoch 92/100 - Loss: 2415.272361621929\n",
      "Epoch 93/100 - Loss: 2373.2355495319594\n",
      "Epoch 94/100 - Loss: 2332.1560343121087\n",
      "Epoch 95/100 - Loss: 2292.012395214621\n",
      "Epoch 96/100 - Loss: 2252.7834921980852\n",
      "Epoch 97/100 - Loss: 2214.4484778570513\n",
      "Epoch 98/100 - Loss: 2176.986808369838\n",
      "Epoch 99/100 - Loss: 2140.3782534283405\n",
      "Epoch 100/100 - Loss: 2104.6029051285855\n",
      "RMSE with bias=True: 0.4079883021319763\n",
      "\n",
      "Best model with bias=True found:\n",
      "Learning Rate: 0.005, Regularization: 0.01, Epochs: 100\n",
      "Best RMSE with bias=True: 0.21412660744410042\n"
     ]
    }
   ],
   "source": [
    "run_experiment(learning_rates, regularizations, n_epochs_values, with_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(predictions, ratings_matrix, k=10, threshold=3.5):\n",
    "    precision_at_k = []\n",
    "    recall_at_k = []\n",
    "    f1_at_k = []\n",
    "\n",
    "    # Duyệt qua từng người dùng (user)\n",
    "    for user_id in range(n_users):\n",
    "        # Lấy các sản phẩm đã có đánh giá của user_id\n",
    "        actual_ratings = ratings_matrix[user_id, :]\n",
    "        actual_items = np.where(actual_ratings >= threshold)[0]  # Các sản phẩm có rating >= threshold\n",
    "        \n",
    "        # Dự đoán xếp hạng cho tất cả các sản phẩm\n",
    "        predicted_ratings = predictions[user_id, :]\n",
    "        \n",
    "        # Lấy K sản phẩm có dự đoán rating cao nhất\n",
    "        top_k_items = np.argsort(predicted_ratings)[-k:]\n",
    "        \n",
    "        # Tính Precision, Recall và F1-Score\n",
    "        actual_set = set(actual_items)\n",
    "        predicted_set = set(top_k_items)\n",
    "\n",
    "        # Tính toán Precision@K, Recall@K và F1-Score@K\n",
    "        precision = len(actual_set.intersection(predicted_set)) / k\n",
    "        recall = len(actual_set.intersection(predicted_set)) / len(actual_set) if len(actual_set) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "        precision_at_k.append(precision)\n",
    "        recall_at_k.append(recall)\n",
    "        f1_at_k.append(f1)\n",
    "\n",
    "    # Tính trung bình các chỉ số\n",
    "    avg_precision_at_k = np.mean(precision_at_k)\n",
    "    avg_recall_at_k = np.mean(recall_at_k)\n",
    "    avg_f1_at_k = np.mean(f1_at_k)\n",
    "    return avg_precision_at_k, avg_recall_at_k, avg_f1_at_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Loss: 13755.240960325275\n",
      "Epoch 2/50 - Loss: 12822.137035648131\n",
      "Epoch 3/50 - Loss: 12195.022219030001\n",
      "Epoch 4/50 - Loss: 11672.843986416336\n",
      "Epoch 5/50 - Loss: 11193.750696229179\n",
      "Epoch 6/50 - Loss: 10724.240148480327\n",
      "Epoch 7/50 - Loss: 10241.773233857977\n",
      "Epoch 8/50 - Loss: 9734.787406869733\n",
      "Epoch 9/50 - Loss: 9209.193738303922\n",
      "Epoch 10/50 - Loss: 8688.361167542578\n",
      "Epoch 11/50 - Loss: 8195.928625097627\n",
      "Epoch 12/50 - Loss: 7736.6756789786505\n",
      "Epoch 13/50 - Loss: 7299.324940612033\n",
      "Epoch 14/50 - Loss: 6872.293418052028\n",
      "Epoch 15/50 - Loss: 6451.6755220447585\n",
      "Epoch 16/50 - Loss: 6039.892307341626\n",
      "Epoch 17/50 - Loss: 5641.791226239047\n",
      "Epoch 18/50 - Loss: 5261.706936838296\n",
      "Epoch 19/50 - Loss: 4902.178315244673\n",
      "Epoch 20/50 - Loss: 4563.967190205253\n",
      "Epoch 21/50 - Loss: 4246.672170424002\n",
      "Epoch 22/50 - Loss: 3949.3549595766376\n",
      "Epoch 23/50 - Loss: 3670.937702547439\n",
      "Epoch 24/50 - Loss: 3410.3815755824676\n",
      "Epoch 25/50 - Loss: 3166.737139624466\n",
      "Epoch 26/50 - Loss: 2939.1405507620398\n",
      "Epoch 27/50 - Loss: 2726.794056766652\n",
      "Epoch 28/50 - Loss: 2528.9453836061016\n",
      "Epoch 29/50 - Loss: 2344.8702447881283\n",
      "Epoch 30/50 - Loss: 2173.859062160862\n",
      "Epoch 31/50 - Loss: 2015.2082749575882\n",
      "Epoch 32/50 - Loss: 1868.2162510479184\n",
      "Epoch 33/50 - Loss: 1732.1833378688664\n",
      "Epoch 34/50 - Loss: 1606.4151259244184\n",
      "Epoch 35/50 - Loss: 1490.227728779229\n",
      "Epoch 36/50 - Loss: 1382.953877354912\n",
      "Epoch 37/50 - Loss: 1283.9488341089186\n",
      "Epoch 38/50 - Loss: 1192.5954496129507\n",
      "Epoch 39/50 - Loss: 1108.3080082615888\n",
      "Epoch 40/50 - Loss: 1030.5347744012079\n",
      "Epoch 41/50 - Loss: 958.7593285841173\n",
      "Epoch 42/50 - Loss: 892.5008796059393\n",
      "Epoch 43/50 - Loss: 831.3137707276054\n",
      "Epoch 44/50 - Loss: 774.786390926651\n",
      "Epoch 45/50 - Loss: 722.5396737892147\n",
      "Epoch 46/50 - Loss: 674.2253315187103\n",
      "Epoch 47/50 - Loss: 629.5239375845094\n",
      "Epoch 48/50 - Loss: 588.1429425279249\n",
      "Epoch 49/50 - Loss: 549.8146843936705\n",
      "Epoch 50/50 - Loss: 514.2944377134664\n",
      "Best Model Results:\n",
      "Precision@10: 0.0165\n",
      "Recall@10: 0.1563\n",
      "F1-Score@10: 0.0297\n"
     ]
    }
   ],
   "source": [
    "def evaluate_best_model(best_params, ratings_matrix, n_users, n_items, n_factors=20, k=10, with_bias=False):\n",
    "    # Lấy các tham số tốt nhất từ kết quả run_experiment\n",
    "    learning_rate, regularization, n_epochs = best_params\n",
    "\n",
    "    # Khởi tạo các yếu tố ẩn và bias\n",
    "    user_factors = np.random.normal(0, 0.1, (n_users, n_factors))\n",
    "    item_factors = np.random.normal(0, 0.1, (n_items, n_factors))\n",
    "    user_bias = np.zeros(n_users) if with_bias else None\n",
    "    item_bias = np.zeros(n_items) if with_bias else None\n",
    "    global_bias = np.mean(ratings_matrix[ratings_matrix > 0]) if with_bias else None\n",
    "\n",
    "    # Chạy SGD với bộ tham số tốt nhất\n",
    "    user_factors, item_factors, user_bias, item_bias = sgd(\n",
    "        ratings_matrix, user_factors, item_factors, user_bias, item_bias, global_bias, learning_rate, regularization, n_epochs, with_bias\n",
    "    )\n",
    "\n",
    "    # Dự đoán kết quả\n",
    "    predictions = global_bias + user_bias[:, np.newaxis] + item_bias[np.newaxis, :] + np.dot(user_factors, item_factors.T) if with_bias else np.dot(user_factors, item_factors.T)\n",
    "\n",
    "    # Tính toán Precision@K, Recall@K và F1-Score@K\n",
    "    precision_at_k, recall_at_k, f1_at_k = evaluate_metrics(predictions, ratings_matrix, k=k)\n",
    "\n",
    "    # In kết quả\n",
    "    print(f\"Best Model Results:\")\n",
    "    print(f\"Precision@{k}: {precision_at_k:.4f}\")\n",
    "    print(f\"Recall@{k}: {recall_at_k:.4f}\")\n",
    "    print(f\"F1-Score@{k}: {f1_at_k:.4f}\")\n",
    "\n",
    "# Sau khi có bộ tham số tốt nhất từ run_experiment, bạn có thể gọi hàm này\n",
    "best_params = (0.01, 0.005, 50)  # Ví dụ bộ tham số tốt nhất từ kết quả run_experiment\n",
    "evaluate_best_model(best_params, ratings_matrix, n_users, n_items, n_factors=20, k=10, with_bias=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
